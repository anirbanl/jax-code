{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jax_autodiff_cookbook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNVjsBkqSKQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax.numpy as np\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "\n",
        "key = random.PRNGKey(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KbAmjnxSRlM",
        "colab_type": "code",
        "outputId": "328f3e5f-4af1-4672-f9bc-2f58f4533fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grad_tanh = grad(np.tanh)\n",
        "print(grad_tanh(2.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.070650935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auht_V4xKpQR",
        "colab_type": "code",
        "outputId": "0e090506-f6ee-4007-c408-744e93299aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(grad(grad(np.tanh))(2.0))\n",
        "print(grad(grad(grad(np.tanh)))(2.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.13621889\n",
            "0.2526544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQRtwX5MKyIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 0.5 * (np.tanh(x / 2) + 1)\n",
        "\n",
        "# Outputs probability of a label being true.\n",
        "def predict(W, b, inputs):\n",
        "    return sigmoid(np.dot(inputs, W) + b)\n",
        "\n",
        "# Build a toy dataset.\n",
        "inputs = np.array([[0.52, 1.12,  0.77],\n",
        "                   [0.88, -1.08, 0.15],\n",
        "                   [0.52, 0.06, -1.30],\n",
        "                   [0.74, -2.49, 1.39]])\n",
        "targets = np.array([True, True, False, True])\n",
        "\n",
        "# Training loss is the negative log-likelihood of the training examples.\n",
        "def loss(W, b):\n",
        "    preds = predict(W, b, inputs)\n",
        "    label_probs = preds * targets + (1 - preds) * (1 - targets)\n",
        "    return -np.sum(np.log(label_probs))\n",
        "\n",
        "# Initialize random model coefficients\n",
        "key, W_key, b_key = random.split(key, 3)\n",
        "W = random.normal(W_key, (3,))\n",
        "b = random.normal(b_key, ())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhFvKz8mK0mW",
        "colab_type": "code",
        "outputId": "28ada5e3-5561-44fc-f794-12974bb8daca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Differentiate `loss` with respect to the first positional argument:\n",
        "W_grad = grad(loss, argnums=0)(W, b)\n",
        "print('W_grad', W_grad)\n",
        "\n",
        "# Since argnums=0 is the default, this does the same thing:\n",
        "W_grad = grad(loss)(W, b)\n",
        "print('W_grad', W_grad)\n",
        "\n",
        "# But we can choose different values too, and drop the keyword:\n",
        "b_grad = grad(loss, 1)(W, b)\n",
        "print('b_grad', b_grad)\n",
        "\n",
        "# Including tuple values\n",
        "W_grad, b_grad = grad(loss, (0, 1))(W, b)\n",
        "print('W_grad', W_grad)\n",
        "print('b_grad', b_grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_grad [-0.16965576 -0.8774645  -1.4901344 ]\n",
            "W_grad [-0.16965576 -0.8774645  -1.4901344 ]\n",
            "b_grad -0.29227236\n",
            "W_grad [-0.16965576 -0.8774645  -1.4901344 ]\n",
            "b_grad -0.29227236\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_hRMrDiK8gH",
        "colab_type": "code",
        "outputId": "eb1fb0af-7463-49cb-853a-996518a4356f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def loss2(params_dict):\n",
        "    preds = predict(params_dict['W'], params_dict['b'], inputs)\n",
        "    label_probs = preds * targets + (1 - preds) * (1 - targets)\n",
        "    return -np.sum(np.log(label_probs))\n",
        "\n",
        "print(grad(loss2)({'W': W, 'b': b}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'W': DeviceArray([-0.16965576, -0.8774645 , -1.4901344 ], dtype=float32), 'b': DeviceArray(-0.29227236, dtype=float32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-5WqgJuLERw",
        "colab_type": "code",
        "outputId": "a531897a-83c3-4339-a47c-aa7d3db0575e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from jax import value_and_grad\n",
        "loss_value, Wb_grad = value_and_grad(loss, (0, 1))(W, b)\n",
        "print('loss value', loss_value)\n",
        "print('loss value', loss(W, b))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss value 3.051939\n",
            "loss value 3.051939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkeIF8oJLGMn",
        "colab_type": "code",
        "outputId": "17ef8b9d-29aa-4283-9666-92d049dc8a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Set a step size for finite differences calculations\n",
        "eps = 1e-4\n",
        "\n",
        "# Check b_grad with scalar finite differences\n",
        "b_grad_numerical = (loss(W, b + eps / 2.) - loss(W, b - eps / 2.)) / eps\n",
        "print('b_grad_numerical', b_grad_numerical)\n",
        "print('b_grad_autodiff', grad(loss, 1)(W, b))\n",
        "\n",
        "# Check W_grad with finite differences in a random direction\n",
        "key, subkey = random.split(key)\n",
        "vec = random.normal(subkey, W.shape)\n",
        "unitvec = vec / np.sqrt(np.vdot(vec, vec))\n",
        "W_grad_numerical = (loss(W + eps / 2. * unitvec, b) - loss(W - eps / 2. * unitvec, b)) / eps\n",
        "print('W_dirderiv_numerical', W_grad_numerical)\n",
        "print('W_dirderiv_autodiff', np.vdot(grad(loss)(W, b), unitvec))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b_grad_numerical -0.29563904\n",
            "b_grad_autodiff -0.29227236\n",
            "W_dirderiv_numerical -0.19788742\n",
            "W_dirderiv_autodiff -0.19909099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1REQ0nXwLQAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from jax.test_util import check_grads\n",
        "check_grads(loss, (W, b), order=2)  # check up to 2nd order derivatives"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUmH3t95MW4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def hvp(f, x, v):\n",
        "    return grad(lambda x: np.vdot(grad(f)(x), v))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZKSL5QbOkF0",
        "colab_type": "code",
        "outputId": "acebd7c7-4681-4ae6-fb7c-5e6c374a883d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from jax import jacfwd, jacrev\n",
        "\n",
        "# Isolate the function from the weight matrix to the predictions\n",
        "f = lambda W: predict(W, b, inputs)\n",
        "\n",
        "J = jacfwd(f)(W)\n",
        "print(\"jacfwd result, with shape\", J.shape)\n",
        "print(J)\n",
        "\n",
        "J = jacrev(f)(W)\n",
        "print(\"jacrev result, with shape\", J.shape)\n",
        "print(J)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jacfwd result, with shape (4, 3)\n",
            "[[ 0.05981756  0.12883782  0.088576  ]\n",
            " [ 0.04015914 -0.04928622  0.00684531]\n",
            " [ 0.12188289  0.01406341 -0.3047072 ]\n",
            " [ 0.00140428 -0.00472522  0.00263777]]\n",
            "jacrev result, with shape (4, 3)\n",
            "[[ 0.05981756  0.12883782  0.088576  ]\n",
            " [ 0.04015914 -0.04928622  0.00684531]\n",
            " [ 0.12188289  0.01406341 -0.3047072 ]\n",
            " [ 0.00140428 -0.00472522  0.00263777]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcKe3_O0OpIi",
        "colab_type": "code",
        "outputId": "da2aec6f-208d-46fc-ecb8-4ad3db8f2ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "def predict_dict(params, inputs):\n",
        "    return predict(params['W'], params['b'], inputs)\n",
        "\n",
        "J_dict = jacrev(predict_dict)({'W': W, 'b': b}, inputs)\n",
        "for k, v in J_dict.items():\n",
        "    print(\"Jacobian from {} to logits is\".format(k))\n",
        "    print(v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Jacobian from W to logits is\n",
            "[[ 0.05981756  0.12883782  0.088576  ]\n",
            " [ 0.04015914 -0.04928622  0.00684531]\n",
            " [ 0.12188289  0.01406341 -0.3047072 ]\n",
            " [ 0.00140428 -0.00472522  0.00263777]]\n",
            "Jacobian from b to logits is\n",
            "[0.11503378 0.04563539 0.23439017 0.00189768]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdPRjNQoXFlm",
        "colab_type": "code",
        "outputId": "aaf8850c-5cbe-425c-e06a-603fd788bca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "def hessian(f):\n",
        "    return jacfwd(jacrev(f))\n",
        "\n",
        "H = hessian(f)(W)\n",
        "print(\"hessian, with shape\", H.shape)\n",
        "print(H)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hessian, with shape (4, 3, 3)\n",
            "[[[ 0.02285465  0.0492254   0.03384246]\n",
            "  [ 0.0492254   0.10602394  0.07289147]\n",
            "  [ 0.03384246  0.07289146  0.05011288]]\n",
            "\n",
            " [[-0.03195214  0.03921399 -0.00544639]\n",
            "  [ 0.03921399 -0.04812626  0.0066842 ]\n",
            "  [-0.00544639  0.0066842  -0.00092836]]\n",
            "\n",
            " [[-0.01583708 -0.00182736  0.03959271]\n",
            "  [-0.00182736 -0.00021085  0.00456839]\n",
            "  [ 0.03959271  0.00456839 -0.09898177]]\n",
            "\n",
            " [[-0.00103522  0.00348336 -0.00194453]\n",
            "  [ 0.00348336 -0.01172105  0.00654308]\n",
            "  [-0.00194453  0.00654308 -0.00365256]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zcJCxp_T6Op",
        "colab_type": "code",
        "outputId": "3d739e2f-6459-4ce3-d283-a620cc3641b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from jax import jvp\n",
        "\n",
        "# Isolate the function from the weight matrix to the predictions\n",
        "f = lambda W: predict(W, b, inputs)\n",
        "\n",
        "key, subkey = random.split(key)\n",
        "v = random.normal(subkey, W.shape)\n",
        "\n",
        "# Push forward the vector `v` along `f` evaluated at `W`\n",
        "y, u = jvp(f, (W,), (v,))\n",
        "print(y,u)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.13262251 0.952067   0.6249393  0.99809873] [-2.9395583e-01 -4.7359422e-02 -1.2595835e-01 -1.5855546e-04]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqz0tkrgUClr",
        "colab_type": "code",
        "outputId": "7c9968de-7681-4172-ecfe-3878ffb5e60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from jax import vjp\n",
        "\n",
        "# Isolate the function from the weight matrix to the predictions\n",
        "f = lambda W: predict(W, b, inputs)\n",
        "\n",
        "y, vjp_fun = vjp(f, W)\n",
        "\n",
        "key, subkey = random.split(key)\n",
        "u = random.normal(subkey, y.shape)\n",
        "\n",
        "# Pull back the covector `u` along `f` evaluated at `W`\n",
        "v = vjp_fun(u)\n",
        "print(y,v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.13262251 0.952067   0.6249393  0.99809873] (DeviceArray([ 0.1710469 , -0.02961703, -0.36015445], dtype=float32),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIC0DGg2V2KP",
        "colab_type": "code",
        "outputId": "6abe0b1e-a994-497a-82fd-6537bd4ac7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from jax import jvp, grad\n",
        "\n",
        "# forward-over-reverse\n",
        "def hvp(f, primals, tangents):\n",
        "  return jvp(grad(f), primals, tangents)[1]\n",
        "\n",
        "# reverse-over-forward\n",
        "def hvp_revfwd(f, primals, tangents):\n",
        "  g = lambda primals: jvp(f, primals, tangents)[1]\n",
        "  return grad(g)(primals)\n",
        "\n",
        "# reverse-over-reverse, only works for single arguments\n",
        "def hvp_revrev(f, primals, tangents):\n",
        "  x, = primals\n",
        "  v, = tangents\n",
        "  return grad(lambda x: np.vdot(grad(f)(x), v))(x)\n",
        "\n",
        "def f(X):\n",
        "  return np.sum(np.tanh(X)**2)\n",
        "\n",
        "key, subkey1, subkey2 = random.split(key, 3)\n",
        "X = random.normal(subkey1, (30, 40))\n",
        "V = random.normal(subkey2, (30, 40))\n",
        "\n",
        "ans1 = hvp(f, (X,), (V,))\n",
        "ans2 = np.tensordot(hessian(f)(X), V, 2)\n",
        "\n",
        "print(np.allclose(ans1, ans2, 1e-4, 1e-4))\n",
        "\n",
        "print(\"Forward over reverse\")\n",
        "%timeit -n10 -r3 hvp(f, (X,), (V,))\n",
        "print(\"Reverse over forward\")\n",
        "%timeit -n10 -r3 hvp_revfwd(f, (X,), (V,))\n",
        "print(\"Reverse over reverse\")\n",
        "%timeit -n10 -r3 hvp_revrev(f, (X,), (V,))\n",
        "\n",
        "print(\"Naive full Hessian materialization\")\n",
        "%timeit -n10 -r3 np.tensordot(hessian(f)(X), V, 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Forward over reverse\n",
            "10 loops, best of 3: 7.93 ms per loop\n",
            "Reverse over forward\n",
            "10 loops, best of 3: 10.1 ms per loop\n",
            "Reverse over reverse\n",
            "10 loops, best of 3: 12 ms per loop\n",
            "Naive full Hessian materialization\n",
            "10 loops, best of 3: 17.1 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EQZIRZqaPEO",
        "colab_type": "code",
        "outputId": "7331aad2-da7d-4330-f261-baf2e45ff6b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Isolate the function from the weight matrix to the predictions\n",
        "f = lambda W: predict(W, b, inputs)\n",
        "\n",
        "# Pull back the covectors `m_i` along `f`, evaluated at `W`, for all `i`.\n",
        "# First, use a list comprehension to loop over rows in the matrix M.\n",
        "def loop_mjp(f, x, M):\n",
        "    y, vjp_fun = vjp(f, x)\n",
        "    return np.vstack([vjp_fun(mi) for mi in M])\n",
        "\n",
        "# Now, use vmap to build a computation that does a single fast matrix-matrix\n",
        "# multiply, rather than an outer loop over vector-matrix multiplies.\n",
        "def vmap_mjp(f, x, M):\n",
        "    y, vjp_fun = vjp(f, x)\n",
        "    return vmap(vjp_fun)(M)\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "num_covecs = 128\n",
        "U = random.normal(key, (num_covecs,) + y.shape)\n",
        "print(U.shape,y)\n",
        "\n",
        "loop_vs = loop_mjp(f, W, M=U)\n",
        "print('Non-vmapped Matrix-Jacobian product')\n",
        "%timeit -n10 -r3 loop_mjp(f, W, M=U)\n",
        "\n",
        "print('\\nVmapped Matrix-Jacobian product')\n",
        "vmap_vs = vmap_mjp(f, W, M=U)\n",
        "%timeit -n10 -r3 vmap_mjp(f, W, M=U)\n",
        "\n",
        "assert np.allclose(loop_vs, vmap_vs), 'Vmap and non-vmapped Matrix-Jacobian Products should be identical'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 4) [0.13262251 0.952067   0.6249393  0.99809873]\n",
            "Non-vmapped Matrix-Jacobian product\n",
            "10 loops, best of 3: 123 ms per loop\n",
            "\n",
            "Vmapped Matrix-Jacobian product\n",
            "10 loops, best of 3: 4.47 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdki8MZBbj4M",
        "colab_type": "code",
        "outputId": "c71adeb1-3f3d-4060-a317-1043e0b4de52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "def loop_jmp(f, x, M):\n",
        "    # jvp immediately returns the primal and tangent values as a tuple,\n",
        "    # so we'll compute and select the tangents in a list comprehension\n",
        "    return np.vstack([jvp(f, (W,), (si,))[1] for si in S])\n",
        "\n",
        "def vmap_jmp(f, x, M):\n",
        "    _jvp = lambda s: jvp(f, (W,), (s,))[1]\n",
        "    return vmap(_jvp)(M)\n",
        "\n",
        "num_vecs = 128\n",
        "S = random.normal(key, (num_vecs,) + W.shape)\n",
        "\n",
        "loop_vs = loop_jmp(f, W, M=S)\n",
        "print('Non-vmapped Jacobian-Matrix product')\n",
        "%timeit -n10 -r3 loop_jmp(f, W, M=S)\n",
        "vmap_vs = vmap_jmp(f, W, M=S)\n",
        "print('\\nVmapped Jacobian-Matrix product')\n",
        "%timeit -n10 -r3 vmap_jmp(f, W, M=S)\n",
        "\n",
        "assert np.allclose(loop_vs, vmap_vs), 'Vmap and non-vmapped Jacobian-Matrix products should be identical'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Non-vmapped Jacobian-Matrix product\n",
            "10 loops, best of 3: 395 ms per loop\n",
            "\n",
            "Vmapped Jacobian-Matrix product\n",
            "10 loops, best of 3: 3.54 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzAGd4KZeh5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from jax import jacrev as builtin_jacrev\n",
        "\n",
        "def our_jacrev(f):\n",
        "    def jacfun(x):\n",
        "        y, vjp_fun = vjp(f, x)\n",
        "        # Use vmap to do a matrix-Jacobian product.\n",
        "        # Here, the matrix is the Euclidean basis, so we get all\n",
        "        # entries in the Jacobian at once.\n",
        "        J, = vmap(vjp_fun, in_axes=0)(np.eye(len(y)))\n",
        "        return J\n",
        "    return jacfun\n",
        "\n",
        "assert np.allclose(builtin_jacrev(f)(W), our_jacrev(f)(W)), 'Incorrect reverse-mode Jacobian results!'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMOMBVinepnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from jax import jacfwd as builtin_jacfwd\n",
        "\n",
        "def our_jacfwd(f):\n",
        "    def jacfun(x):\n",
        "        _jvp = lambda s: jvp(f, (x,), (s,))[1]\n",
        "        Jt =vmap(_jvp, in_axes=1)(np.eye(len(x)))\n",
        "        return np.transpose(Jt)\n",
        "    return jacfun\n",
        "\n",
        "assert np.allclose(builtin_jacfwd(f)(W), our_jacfwd(f)(W)), 'Incorrect forward-mode Jacobian results!'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNpTZqHpfLbB",
        "colab_type": "code",
        "outputId": "d64f66b6-6670-4c6d-d521-b2c2b484b99c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def f(x):\n",
        "    try:\n",
        "        if x < 3:\n",
        "            return 2 * x ** 3\n",
        "        else:\n",
        "            raise ValueError\n",
        "    except ValueError:\n",
        "        return np.pi * x\n",
        "\n",
        "y, f_vjp = vjp(f, 4.)\n",
        "print(jit(f_vjp)(1.))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(DeviceArray(3.1415927, dtype=float32),)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}