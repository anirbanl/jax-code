{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jax_qlearning_cartpole.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirbanl/jax-code/blob/master/rlflax/qlearning/jax_flax_qlearning_cartpole.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJIO3iDY31YN"
      },
      "source": [
        "Based on sources:\n",
        "1. Double DQN paper: https://arxiv.org/pdf/1509.06461.pdf\n",
        "2. Blog: https://medium.com/@parsa_h_m/deep-reinforcement-learning-dqn-double-dqn-dueling-dqn-noisy-dqn-and-dqn-with-prioritized-551f621a9823\n",
        "3. Pytorch code: https://github.com/higgsfield/RL-Adventure/blob/master/1.dqn.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_jS9qg6EG4l",
        "outputId": "780b20f8-6bb8-49ab-978d-4f975ea53a7f"
      },
      "source": [
        "!pip install jax jaxlib flax"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jax in /usr/local/lib/python3.7/dist-packages (0.2.13)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.7/dist-packages (0.1.66+cuda110)\n",
            "Collecting flax\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/21/21ca1f4831ac24646578d2545c4db9a8369b9da4a4b7dcf067feee312b45/flax-0.3.4-py3-none-any.whl (183kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax) (3.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.7/dist-packages (from jax) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jaxlib) (1.4.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from jaxlib) (1.12)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flax) (3.2.2)\n",
            "Collecting optax\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/04/464fa1d12562d191196f2f7f8112d65e22eaaa9a7e2b599f298aeba2ce27/optax-0.0.8-py3-none-any.whl (113kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.7/dist-packages (from flax) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flax) (2.4.7)\n",
            "Collecting chex>=0.0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/b9/445eb59ec23249acffc5322c79b07e20b12dbff45b9c1da6cdae9e947685/chex-0.0.7-py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.1.6)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax->flax) (0.11.1)\n",
            "Installing collected packages: chex, optax, flax\n",
            "Successfully installed chex-0.0.7 flax-0.3.4 optax-0.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt1r4--nEPJm"
      },
      "source": [
        "import gym\n",
        "gym.logger.set_level(40) # suppress warnings (please remove if gives error)\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import jax\n",
        "import jax.numpy as jp\n",
        "from jax.ops import index, index_add, index_update\n",
        "from jax import jit, grad, vmap, random, jacrev, jacobian, jacfwd, value_and_grad\n",
        "from functools import partial\n",
        "from jax.tree_util import tree_multimap  # Element-wise manipulation of collections of numpy arrays\n",
        "from flax import linen as nn           # The Linen API\n",
        "from flax.training import train_state  # Useful dataclass to keep train state\n",
        "import optax                           # Optimizers\n",
        "from typing import Sequence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK9XAT81EWW0"
      },
      "source": [
        "from collections import deque\n",
        "class Memory():\n",
        "    def __init__(self, max_size = 1000):\n",
        "        self.buffer = deque(maxlen=max_size)\n",
        "    \n",
        "    def add(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "            \n",
        "    def sample(self, key, batch_size):\n",
        "        key, _ = jax.random.split(key)\n",
        "        idx = jax.random.choice(key,\n",
        "                               jp.arange(len(self.buffer)), \n",
        "                               shape=(batch_size, ))\n",
        "        # print(f\"\\nIds:{jp.mean(idx)}\\n\")\n",
        "        return [self.buffer[ii] for ii in idx]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtUX4AXiFWVK"
      },
      "source": [
        "train_episodes = 1000          # max number of episodes to learn from\n",
        "max_steps = 200                # max steps in an episode\n",
        "gamma = 0.99                   # future reward discount\n",
        "\n",
        "# Exploration parameters\n",
        "explore_start = 1.0            # exploration probability at start\n",
        "explore_stop = 0.01            # minimum exploration probability \n",
        "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
        "\n",
        "# Network parameters\n",
        "hidden_size = 64               # number of units in each Q-network hidden layer\n",
        "learning_rate = 1e-4         # Q-network learning rate\n",
        "\n",
        "# Memory parameters\n",
        "memory_size = 10000            # memory capacity\n",
        "batch_size = 20                # experience mini-batch size\n",
        "pretrain_length = batch_size   # number experiences to pretrain the memory"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSJfnThHFouD"
      },
      "source": [
        "#Define Q-network\n",
        "class QNetwork:\n",
        "    def __init__(self, rng, env, learning_rate=0.01, state_size=4, \n",
        "                 action_size=2, hidden_size=10, \n",
        "                 name='QNetwork'):\n",
        "        self.key = rng\n",
        "        self.env = env\n",
        "        # print(f\"QNetwork rng:{rng}\")\n",
        "\n",
        "        class Model(nn.Module):\n",
        "            features: Sequence[int]\n",
        "\n",
        "            @nn.compact\n",
        "            def __call__(self, x):\n",
        "                x = nn.relu(nn.Dense(self.features[0])(x))\n",
        "                x = nn.relu(nn.Dense(self.features[1])(x))\n",
        "                x = nn.Dense(self.features[2])(x)\n",
        "                return x\n",
        "\n",
        "        def create_train_state(rng, learning_rate, s_size, h_size, a_size):\n",
        "            \"\"\"Creates initial `TrainState`.\"\"\"\n",
        "            model = Model(features=[hidden_size, hidden_size, a_size])\n",
        "            params = model.init(rng, jp.ones((s_size, )))#['params']\n",
        "            tx = optax.adam(learning_rate)\n",
        "            return train_state.TrainState.create(\n",
        "                apply_fn=model.apply, params=params, tx=tx)\n",
        "\n",
        "        self.ts = create_train_state(rng, learning_rate, state_size, hidden_size, action_size)\n",
        "\n",
        "        @jit\n",
        "        def train_step(ts, inputs, actions, targets):\n",
        "\n",
        "            def loss_fun(params, inputs, actions, targets):\n",
        "                output = ts.apply_fn(params, inputs)\n",
        "                selectedq = jp.sum(actions*output, axis=-1)\n",
        "                diff = selectedq - jax.lax.stop_gradient(targets)\n",
        "                return jp.mean(diff**2)\n",
        "\n",
        "            loss, g = value_and_grad(loss_fun)(ts.params, inputs, actions, targets)\n",
        "            return ts.apply_gradients(grads=g), loss\n",
        "\n",
        "        self.train_fn = train_step\n",
        "\n",
        "\n",
        "    def act(self, state, explore_p):\n",
        "        self.key, _ = jax.random.split(self.key)\n",
        "        # print(f\"Act key:{self.key}\")\n",
        "        uf = jax.random.uniform(self.key, (1,), minval=0.0, maxval=1.0)[0]\n",
        "        if explore_p > uf:\n",
        "            # Make a random action\n",
        "            action = self.env.action_space.sample()\n",
        "        else:\n",
        "            # Get action from Q-network\n",
        "            qvalues = self.ts.apply_fn(self.ts.params, state)\n",
        "            action = jp.argmax(qvalues).item()\n",
        "        return action\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0fPvqRcLdf4"
      },
      "source": [
        "def init_memory(env):\n",
        "    # Initialize the simulation\n",
        "    env.reset()\n",
        "    # Take one random step to get the pole and cart moving\n",
        "    state, reward, done, _ = env.step(env.action_space.sample())\n",
        "    # print(f\"@@@@@@ Env init state:{state} @@@@@@\")\n",
        "\n",
        "    memory = Memory(max_size=memory_size)\n",
        "\n",
        "    # Make a bunch of random actions and store the experiences\n",
        "    for ii in range(pretrain_length):\n",
        "        # Uncomment the line below to watch the simulation\n",
        "        # env.render()\n",
        "\n",
        "        # Make a random action\n",
        "        action = env.action_space.sample()\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        # print(f\"@@@@@@ Env action:{action} @@@@@@\")\n",
        "        # print(f\"@@@@@@ Env next state:{next_state} @@@@@@\")\n",
        "\n",
        "        if done:\n",
        "            # The simulation fails so no next state\n",
        "            next_state = jp.zeros(state.shape)\n",
        "            # Add experience to memory\n",
        "            memory.add((state, action, reward, next_state))\n",
        "            \n",
        "            # Start new episode\n",
        "            env.reset()\n",
        "            # Take one random step to get the pole and cart moving\n",
        "            state, reward, done, _ = env.step(env.action_space.sample())\n",
        "        else:\n",
        "            # Add experience to memory\n",
        "            memory.add((state, action, reward, next_state))\n",
        "            state = next_state\n",
        "    return memory, state"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vpr3LNUMkaG"
      },
      "source": [
        "# Now train with experiences\n",
        "def one_hot(x, k, dtype=jp.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return jp.array(x[:, None] == jp.arange(k), dtype)\n",
        "\n",
        "\n",
        "def train(rng, env, mainQN):\n",
        "    # print(f\"train rng:{rng}\")\n",
        "    rewards_list = []    \n",
        "    step = 0\n",
        "    memory, state = init_memory(env)\n",
        "    for ep in range(1, train_episodes):\n",
        "        total_reward = 0\n",
        "        t = 0\n",
        "        while t < max_steps:\n",
        "            step += 1\n",
        "            # Uncomment this next line to watch the training\n",
        "            # env.render() \n",
        "            \n",
        "            # Explore or Exploit\n",
        "            explore_p = explore_stop + (explore_start - explore_stop)*jp.exp(-decay_rate*step) \n",
        "            action = mainQN.act(state, explore_p)\n",
        "            \n",
        "            # Take action, get new state and reward\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            # print(f\"State:{state}\")\n",
        "            # print(f\"Reward:{reward}\")\n",
        "            # print(f\"Action:{action}\")\n",
        "            # print(f\"Done:{done}\\n\")\n",
        "\n",
        "            total_reward += reward\n",
        "            \n",
        "            if done:\n",
        "                # the episode ends so no next state\n",
        "                next_state = jp.zeros(state.shape)\n",
        "                t = max_steps\n",
        "                \n",
        "                print('Episode: {}'.format(ep),\n",
        "                    'Total reward: {}'.format(total_reward),\n",
        "                    'Training loss: {:.4f}'.format(loss),\n",
        "                    'Explore P: {:.4f}'.format(explore_p))\n",
        "                rewards_list.append((ep, total_reward))\n",
        "                \n",
        "                # Add experience to memory\n",
        "                memory.add((state, action, reward, next_state))\n",
        "                \n",
        "                # Start new episode\n",
        "                env.reset()\n",
        "                # Take one random step to get the pole and cart moving\n",
        "                state, reward, done, _ = env.step(env.action_space.sample())\n",
        "\n",
        "            else:\n",
        "                # Add experience to memory\n",
        "                memory.add((state, action, reward, next_state))\n",
        "                state = next_state\n",
        "                t += 1\n",
        "            \n",
        "            # Sample mini-batch from memory\n",
        "            batch = memory.sample(rng, batch_size)\n",
        "            states = jp.array([each[0] for each in batch])\n",
        "            actions = one_hot(jp.array([each[1] for each in batch]), 2)\n",
        "            rewards = jp.array([each[2] for each in batch])\n",
        "            next_states = jp.array([each[3] for each in batch])\n",
        "            \n",
        "            # Train network\n",
        "            target_Qs = mainQN.ts.apply_fn(mainQN.ts.params, next_states)\n",
        "            \n",
        "            # Set target_Qs to 0 for states where episode ends\n",
        "            episode_ends = (next_states == jp.zeros(states[0].shape)).all(axis=1)\n",
        "            new_target_Qs = index_update(target_Qs, index[episode_ends], (0, 0))\n",
        "            target_Qs = new_target_Qs\n",
        "            \n",
        "            targets = rewards + gamma * jp.max(target_Qs, axis=1)\n",
        "            # print(states.shape, targets.shape, targets)\n",
        "            mainQN.ts, loss = mainQN.train_fn(mainQN.ts, states, actions, targets)\n",
        "\n",
        "    return rewards_list\n",
        "\n",
        "def plot_scores(rewards_list):\n",
        "    def running_mean(x, N):\n",
        "        cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
        "        return (cumsum[N:] - cumsum[:-N]) / N\n",
        "    eps, rews = np.array(rewards_list).T\n",
        "    smoothed_rews = running_mean(rews, 10)\n",
        "    plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
        "    plt.plot(eps, rews, color='grey', alpha=0.3)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Total Reward')\n",
        "    plt.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeurKJ6oNcZF",
        "outputId": "59ed425f-6ebd-49f4-c5a9-a33eb7813e18"
      },
      "source": [
        "def main():\n",
        "    seed = 0\n",
        "    env = gym.make('CartPole-v0')\n",
        "    env.seed(seed)\n",
        "    env.action_space.seed(seed)\n",
        "    print('observation space:', env.observation_space)\n",
        "    print('action space:', env.action_space.n)\n",
        "    rng = jax.random.PRNGKey(seed)\n",
        "    mainQN = QNetwork(rng, env, name='main', hidden_size=hidden_size, learning_rate=learning_rate)\n",
        "    rewards_list = train(rng, env, mainQN)\n",
        "    plot_scores(rewards_list)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
            "action space: 2\n",
            "Episode: 1 Total reward: 31.0 Training loss: 1.8259 Explore P: 0.9969\n",
            "Episode: 2 Total reward: 54.0 Training loss: 1.7116 Explore P: 0.9916\n",
            "Episode: 3 Total reward: 28.0 Training loss: 2.2000 Explore P: 0.9889\n",
            "Episode: 4 Total reward: 21.0 Training loss: 1.5221 Explore P: 0.9868\n",
            "Episode: 5 Total reward: 8.0 Training loss: 1.6395 Explore P: 0.9860\n",
            "Episode: 6 Total reward: 13.0 Training loss: 2.3222 Explore P: 0.9848\n",
            "Episode: 7 Total reward: 20.0 Training loss: 1.7800 Explore P: 0.9828\n",
            "Episode: 8 Total reward: 35.0 Training loss: 2.0489 Explore P: 0.9794\n",
            "Episode: 9 Total reward: 27.0 Training loss: 2.1992 Explore P: 0.9768\n",
            "Episode: 10 Total reward: 22.0 Training loss: 1.9105 Explore P: 0.9747\n",
            "Episode: 11 Total reward: 15.0 Training loss: 2.5201 Explore P: 0.9732\n",
            "Episode: 12 Total reward: 28.0 Training loss: 2.4345 Explore P: 0.9705\n",
            "Episode: 13 Total reward: 10.0 Training loss: 2.9751 Explore P: 0.9696\n",
            "Episode: 14 Total reward: 16.0 Training loss: 2.6271 Explore P: 0.9681\n",
            "Episode: 15 Total reward: 10.0 Training loss: 3.0990 Explore P: 0.9671\n",
            "Episode: 16 Total reward: 21.0 Training loss: 1.9696 Explore P: 0.9651\n",
            "Episode: 17 Total reward: 15.0 Training loss: 8.1083 Explore P: 0.9637\n",
            "Episode: 18 Total reward: 10.0 Training loss: 5.8527 Explore P: 0.9627\n",
            "Episode: 19 Total reward: 33.0 Training loss: 3.7248 Explore P: 0.9596\n",
            "Episode: 20 Total reward: 26.0 Training loss: 2.9975 Explore P: 0.9571\n",
            "Episode: 21 Total reward: 17.0 Training loss: 3.0993 Explore P: 0.9555\n",
            "Episode: 22 Total reward: 11.0 Training loss: 3.6179 Explore P: 0.9545\n",
            "Episode: 23 Total reward: 23.0 Training loss: 4.2853 Explore P: 0.9523\n",
            "Episode: 24 Total reward: 14.0 Training loss: 4.6306 Explore P: 0.9510\n",
            "Episode: 25 Total reward: 18.0 Training loss: 4.6807 Explore P: 0.9493\n",
            "Episode: 26 Total reward: 27.0 Training loss: 4.0798 Explore P: 0.9467\n",
            "Episode: 27 Total reward: 17.0 Training loss: 3.5891 Explore P: 0.9451\n",
            "Episode: 28 Total reward: 31.0 Training loss: 14.4876 Explore P: 0.9423\n",
            "Episode: 29 Total reward: 63.0 Training loss: 4.7503 Explore P: 0.9364\n",
            "Episode: 30 Total reward: 11.0 Training loss: 5.0181 Explore P: 0.9354\n",
            "Episode: 31 Total reward: 29.0 Training loss: 24.3917 Explore P: 0.9327\n",
            "Episode: 32 Total reward: 36.0 Training loss: 4.7422 Explore P: 0.9294\n",
            "Episode: 33 Total reward: 18.0 Training loss: 4.2146 Explore P: 0.9277\n",
            "Episode: 34 Total reward: 20.0 Training loss: 10.7840 Explore P: 0.9259\n",
            "Episode: 35 Total reward: 8.0 Training loss: 6.1613 Explore P: 0.9252\n",
            "Episode: 36 Total reward: 25.0 Training loss: 14.4559 Explore P: 0.9229\n",
            "Episode: 37 Total reward: 15.0 Training loss: 16.0378 Explore P: 0.9215\n",
            "Episode: 38 Total reward: 17.0 Training loss: 17.1916 Explore P: 0.9200\n",
            "Episode: 39 Total reward: 9.0 Training loss: 22.8107 Explore P: 0.9191\n",
            "Episode: 40 Total reward: 16.0 Training loss: 5.1523 Explore P: 0.9177\n",
            "Episode: 41 Total reward: 21.0 Training loss: 5.9874 Explore P: 0.9158\n",
            "Episode: 42 Total reward: 14.0 Training loss: 6.5615 Explore P: 0.9145\n",
            "Episode: 43 Total reward: 13.0 Training loss: 6.3152 Explore P: 0.9133\n",
            "Episode: 44 Total reward: 13.0 Training loss: 6.8131 Explore P: 0.9122\n",
            "Episode: 45 Total reward: 14.0 Training loss: 9.9096 Explore P: 0.9109\n",
            "Episode: 46 Total reward: 16.0 Training loss: 7.9821 Explore P: 0.9095\n",
            "Episode: 47 Total reward: 12.0 Training loss: 23.2153 Explore P: 0.9084\n",
            "Episode: 48 Total reward: 40.0 Training loss: 14.1710 Explore P: 0.9048\n",
            "Episode: 49 Total reward: 17.0 Training loss: 13.0533 Explore P: 0.9033\n",
            "Episode: 50 Total reward: 21.0 Training loss: 9.1359 Explore P: 0.9014\n",
            "Episode: 51 Total reward: 20.0 Training loss: 7.9412 Explore P: 0.8996\n",
            "Episode: 52 Total reward: 13.0 Training loss: 20.3329 Explore P: 0.8985\n",
            "Episode: 53 Total reward: 8.0 Training loss: 14.4499 Explore P: 0.8978\n",
            "Episode: 54 Total reward: 22.0 Training loss: 8.3270 Explore P: 0.8958\n",
            "Episode: 55 Total reward: 23.0 Training loss: 31.7680 Explore P: 0.8938\n",
            "Episode: 56 Total reward: 30.0 Training loss: 9.3125 Explore P: 0.8911\n",
            "Episode: 57 Total reward: 13.0 Training loss: 55.7073 Explore P: 0.8900\n",
            "Episode: 58 Total reward: 21.0 Training loss: 16.0677 Explore P: 0.8881\n",
            "Episode: 59 Total reward: 17.0 Training loss: 16.8897 Explore P: 0.8866\n",
            "Episode: 60 Total reward: 52.0 Training loss: 30.6914 Explore P: 0.8821\n",
            "Episode: 61 Total reward: 19.0 Training loss: 24.9566 Explore P: 0.8804\n",
            "Episode: 62 Total reward: 10.0 Training loss: 26.6910 Explore P: 0.8796\n",
            "Episode: 63 Total reward: 20.0 Training loss: 8.5296 Explore P: 0.8778\n",
            "Episode: 64 Total reward: 35.0 Training loss: 28.6571 Explore P: 0.8748\n",
            "Episode: 65 Total reward: 11.0 Training loss: 24.8822 Explore P: 0.8739\n",
            "Episode: 66 Total reward: 15.0 Training loss: 25.5215 Explore P: 0.8726\n",
            "Episode: 67 Total reward: 9.0 Training loss: 50.8190 Explore P: 0.8718\n",
            "Episode: 68 Total reward: 23.0 Training loss: 29.2302 Explore P: 0.8698\n",
            "Episode: 69 Total reward: 43.0 Training loss: 21.0477 Explore P: 0.8661\n",
            "Episode: 70 Total reward: 9.0 Training loss: 24.9498 Explore P: 0.8653\n",
            "Episode: 71 Total reward: 16.0 Training loss: 25.6054 Explore P: 0.8640\n",
            "Episode: 72 Total reward: 8.0 Training loss: 15.5495 Explore P: 0.8633\n",
            "Episode: 73 Total reward: 10.0 Training loss: 67.4527 Explore P: 0.8624\n",
            "Episode: 74 Total reward: 11.0 Training loss: 25.4925 Explore P: 0.8615\n",
            "Episode: 75 Total reward: 18.0 Training loss: 23.0947 Explore P: 0.8600\n",
            "Episode: 76 Total reward: 12.0 Training loss: 88.6882 Explore P: 0.8590\n",
            "Episode: 77 Total reward: 9.0 Training loss: 41.8311 Explore P: 0.8582\n",
            "Episode: 78 Total reward: 14.0 Training loss: 8.7515 Explore P: 0.8570\n",
            "Episode: 79 Total reward: 32.0 Training loss: 95.5195 Explore P: 0.8543\n",
            "Episode: 80 Total reward: 11.0 Training loss: 6.9502 Explore P: 0.8534\n",
            "Episode: 81 Total reward: 12.0 Training loss: 7.9258 Explore P: 0.8524\n",
            "Episode: 82 Total reward: 9.0 Training loss: 25.3751 Explore P: 0.8516\n",
            "Episode: 83 Total reward: 18.0 Training loss: 48.7170 Explore P: 0.8501\n",
            "Episode: 84 Total reward: 12.0 Training loss: 9.4771 Explore P: 0.8491\n",
            "Episode: 85 Total reward: 26.0 Training loss: 19.9881 Explore P: 0.8469\n",
            "Episode: 86 Total reward: 15.0 Training loss: 7.8967 Explore P: 0.8456\n",
            "Episode: 87 Total reward: 15.0 Training loss: 41.4878 Explore P: 0.8444\n",
            "Episode: 88 Total reward: 8.0 Training loss: 8.2501 Explore P: 0.8437\n",
            "Episode: 89 Total reward: 12.0 Training loss: 27.3545 Explore P: 0.8427\n",
            "Episode: 90 Total reward: 9.0 Training loss: 19.4601 Explore P: 0.8420\n",
            "Episode: 91 Total reward: 15.0 Training loss: 107.3072 Explore P: 0.8407\n",
            "Episode: 92 Total reward: 48.0 Training loss: 22.6264 Explore P: 0.8368\n",
            "Episode: 93 Total reward: 12.0 Training loss: 125.8518 Explore P: 0.8358\n",
            "Episode: 94 Total reward: 15.0 Training loss: 8.9317 Explore P: 0.8345\n",
            "Episode: 95 Total reward: 11.0 Training loss: 114.4914 Explore P: 0.8336\n",
            "Episode: 96 Total reward: 8.0 Training loss: 72.9871 Explore P: 0.8330\n",
            "Episode: 97 Total reward: 8.0 Training loss: 9.4243 Explore P: 0.8323\n",
            "Episode: 98 Total reward: 16.0 Training loss: 10.9976 Explore P: 0.8310\n",
            "Episode: 99 Total reward: 33.0 Training loss: 18.0936 Explore P: 0.8283\n",
            "Episode: 100 Total reward: 15.0 Training loss: 8.4381 Explore P: 0.8271\n",
            "Episode: 101 Total reward: 14.0 Training loss: 85.5379 Explore P: 0.8259\n",
            "Episode: 102 Total reward: 12.0 Training loss: 9.4767 Explore P: 0.8249\n",
            "Episode: 103 Total reward: 16.0 Training loss: 70.1303 Explore P: 0.8236\n",
            "Episode: 104 Total reward: 15.0 Training loss: 81.3371 Explore P: 0.8224\n",
            "Episode: 105 Total reward: 12.0 Training loss: 35.3132 Explore P: 0.8214\n",
            "Episode: 106 Total reward: 31.0 Training loss: 7.6005 Explore P: 0.8189\n",
            "Episode: 107 Total reward: 15.0 Training loss: 59.2375 Explore P: 0.8177\n",
            "Episode: 108 Total reward: 13.0 Training loss: 80.9691 Explore P: 0.8167\n",
            "Episode: 109 Total reward: 13.0 Training loss: 29.0419 Explore P: 0.8156\n",
            "Episode: 110 Total reward: 15.0 Training loss: 7.8529 Explore P: 0.8144\n",
            "Episode: 111 Total reward: 12.0 Training loss: 38.6802 Explore P: 0.8134\n",
            "Episode: 112 Total reward: 11.0 Training loss: 7.7560 Explore P: 0.8126\n",
            "Episode: 113 Total reward: 18.0 Training loss: 9.3328 Explore P: 0.8111\n",
            "Episode: 114 Total reward: 12.0 Training loss: 110.7461 Explore P: 0.8102\n",
            "Episode: 115 Total reward: 17.0 Training loss: 26.7475 Explore P: 0.8088\n",
            "Episode: 116 Total reward: 41.0 Training loss: 38.1498 Explore P: 0.8055\n",
            "Episode: 117 Total reward: 10.0 Training loss: 80.2076 Explore P: 0.8047\n",
            "Episode: 118 Total reward: 25.0 Training loss: 6.8998 Explore P: 0.8027\n",
            "Episode: 119 Total reward: 13.0 Training loss: 88.2866 Explore P: 0.8017\n",
            "Episode: 120 Total reward: 9.0 Training loss: 95.1518 Explore P: 0.8010\n",
            "Episode: 121 Total reward: 17.0 Training loss: 67.3698 Explore P: 0.7997\n",
            "Episode: 122 Total reward: 14.0 Training loss: 45.0661 Explore P: 0.7986\n",
            "Episode: 123 Total reward: 10.0 Training loss: 43.3085 Explore P: 0.7978\n",
            "Episode: 124 Total reward: 17.0 Training loss: 5.7287 Explore P: 0.7964\n",
            "Episode: 125 Total reward: 47.0 Training loss: 118.1822 Explore P: 0.7927\n",
            "Episode: 126 Total reward: 12.0 Training loss: 53.7833 Explore P: 0.7918\n",
            "Episode: 127 Total reward: 24.0 Training loss: 6.8687 Explore P: 0.7899\n",
            "Episode: 128 Total reward: 20.0 Training loss: 106.8474 Explore P: 0.7884\n",
            "Episode: 129 Total reward: 14.0 Training loss: 96.4019 Explore P: 0.7873\n",
            "Episode: 130 Total reward: 14.0 Training loss: 37.4082 Explore P: 0.7862\n",
            "Episode: 131 Total reward: 12.0 Training loss: 7.5340 Explore P: 0.7853\n",
            "Episode: 132 Total reward: 12.0 Training loss: 36.2951 Explore P: 0.7843\n",
            "Episode: 133 Total reward: 8.0 Training loss: 57.9612 Explore P: 0.7837\n",
            "Episode: 134 Total reward: 9.0 Training loss: 7.1186 Explore P: 0.7830\n",
            "Episode: 135 Total reward: 15.0 Training loss: 38.6279 Explore P: 0.7819\n",
            "Episode: 136 Total reward: 15.0 Training loss: 85.0945 Explore P: 0.7807\n",
            "Episode: 137 Total reward: 11.0 Training loss: 65.9567 Explore P: 0.7799\n",
            "Episode: 138 Total reward: 9.0 Training loss: 26.8167 Explore P: 0.7792\n",
            "Episode: 139 Total reward: 13.0 Training loss: 108.4425 Explore P: 0.7782\n",
            "Episode: 140 Total reward: 10.0 Training loss: 122.4668 Explore P: 0.7774\n",
            "Episode: 141 Total reward: 11.0 Training loss: 7.4959 Explore P: 0.7766\n",
            "Episode: 142 Total reward: 27.0 Training loss: 91.2953 Explore P: 0.7745\n",
            "Episode: 143 Total reward: 12.0 Training loss: 98.1720 Explore P: 0.7736\n",
            "Episode: 144 Total reward: 23.0 Training loss: 72.9251 Explore P: 0.7718\n",
            "Episode: 145 Total reward: 17.0 Training loss: 7.6199 Explore P: 0.7705\n",
            "Episode: 146 Total reward: 22.0 Training loss: 33.8744 Explore P: 0.7689\n",
            "Episode: 147 Total reward: 11.0 Training loss: 7.7173 Explore P: 0.7680\n",
            "Episode: 148 Total reward: 17.0 Training loss: 5.7958 Explore P: 0.7667\n",
            "Episode: 149 Total reward: 14.0 Training loss: 8.7247 Explore P: 0.7657\n",
            "Episode: 150 Total reward: 8.0 Training loss: 37.4804 Explore P: 0.7651\n",
            "Episode: 151 Total reward: 15.0 Training loss: 49.3243 Explore P: 0.7639\n",
            "Episode: 152 Total reward: 16.0 Training loss: 7.8427 Explore P: 0.7627\n",
            "Episode: 153 Total reward: 17.0 Training loss: 6.3384 Explore P: 0.7615\n",
            "Episode: 154 Total reward: 27.0 Training loss: 66.7793 Explore P: 0.7594\n",
            "Episode: 155 Total reward: 27.0 Training loss: 68.0436 Explore P: 0.7574\n",
            "Episode: 156 Total reward: 11.0 Training loss: 58.5149 Explore P: 0.7566\n",
            "Episode: 157 Total reward: 13.0 Training loss: 5.5014 Explore P: 0.7556\n",
            "Episode: 158 Total reward: 13.0 Training loss: 42.8452 Explore P: 0.7546\n",
            "Episode: 159 Total reward: 28.0 Training loss: 111.5350 Explore P: 0.7526\n",
            "Episode: 160 Total reward: 23.0 Training loss: 122.2460 Explore P: 0.7509\n",
            "Episode: 161 Total reward: 20.0 Training loss: 96.6482 Explore P: 0.7494\n",
            "Episode: 162 Total reward: 11.0 Training loss: 80.8583 Explore P: 0.7486\n",
            "Episode: 163 Total reward: 8.0 Training loss: 63.8520 Explore P: 0.7480\n",
            "Episode: 164 Total reward: 17.0 Training loss: 55.1592 Explore P: 0.7467\n",
            "Episode: 165 Total reward: 8.0 Training loss: 5.7663 Explore P: 0.7461\n",
            "Episode: 166 Total reward: 31.0 Training loss: 129.5538 Explore P: 0.7439\n",
            "Episode: 167 Total reward: 17.0 Training loss: 111.3189 Explore P: 0.7426\n",
            "Episode: 168 Total reward: 27.0 Training loss: 58.7511 Explore P: 0.7406\n",
            "Episode: 169 Total reward: 15.0 Training loss: 6.9878 Explore P: 0.7395\n",
            "Episode: 170 Total reward: 12.0 Training loss: 126.5512 Explore P: 0.7387\n",
            "Episode: 171 Total reward: 11.0 Training loss: 36.8799 Explore P: 0.7379\n",
            "Episode: 172 Total reward: 13.0 Training loss: 5.7031 Explore P: 0.7369\n",
            "Episode: 173 Total reward: 12.0 Training loss: 82.2256 Explore P: 0.7360\n",
            "Episode: 174 Total reward: 11.0 Training loss: 89.4356 Explore P: 0.7352\n",
            "Episode: 175 Total reward: 11.0 Training loss: 98.5654 Explore P: 0.7344\n",
            "Episode: 176 Total reward: 9.0 Training loss: 51.0750 Explore P: 0.7338\n",
            "Episode: 177 Total reward: 24.0 Training loss: 37.7001 Explore P: 0.7321\n",
            "Episode: 178 Total reward: 22.0 Training loss: 39.3590 Explore P: 0.7305\n",
            "Episode: 179 Total reward: 23.0 Training loss: 6.6909 Explore P: 0.7288\n",
            "Episode: 180 Total reward: 25.0 Training loss: 38.4017 Explore P: 0.7270\n",
            "Episode: 181 Total reward: 20.0 Training loss: 65.6151 Explore P: 0.7256\n",
            "Episode: 182 Total reward: 20.0 Training loss: 7.8244 Explore P: 0.7242\n",
            "Episode: 183 Total reward: 16.0 Training loss: 51.6178 Explore P: 0.7230\n",
            "Episode: 184 Total reward: 11.0 Training loss: 6.4923 Explore P: 0.7222\n",
            "Episode: 185 Total reward: 12.0 Training loss: 133.6774 Explore P: 0.7214\n",
            "Episode: 186 Total reward: 10.0 Training loss: 75.7724 Explore P: 0.7207\n",
            "Episode: 187 Total reward: 23.0 Training loss: 4.9472 Explore P: 0.7190\n",
            "Episode: 188 Total reward: 15.0 Training loss: 36.1508 Explore P: 0.7180\n",
            "Episode: 189 Total reward: 13.0 Training loss: 7.2898 Explore P: 0.7171\n",
            "Episode: 190 Total reward: 19.0 Training loss: 6.6132 Explore P: 0.7157\n",
            "Episode: 191 Total reward: 11.0 Training loss: 5.4964 Explore P: 0.7149\n",
            "Episode: 192 Total reward: 10.0 Training loss: 5.7988 Explore P: 0.7142\n",
            "Episode: 193 Total reward: 9.0 Training loss: 59.0950 Explore P: 0.7136\n",
            "Episode: 194 Total reward: 15.0 Training loss: 95.8743 Explore P: 0.7125\n",
            "Episode: 195 Total reward: 20.0 Training loss: 51.7812 Explore P: 0.7111\n",
            "Episode: 196 Total reward: 16.0 Training loss: 246.2805 Explore P: 0.7100\n",
            "Episode: 197 Total reward: 14.0 Training loss: 5.9767 Explore P: 0.7090\n",
            "Episode: 198 Total reward: 16.0 Training loss: 52.6687 Explore P: 0.7079\n",
            "Episode: 199 Total reward: 20.0 Training loss: 85.0280 Explore P: 0.7065\n",
            "Episode: 200 Total reward: 12.0 Training loss: 5.3474 Explore P: 0.7057\n",
            "Episode: 201 Total reward: 10.0 Training loss: 100.9488 Explore P: 0.7050\n",
            "Episode: 202 Total reward: 12.0 Training loss: 34.6764 Explore P: 0.7042\n",
            "Episode: 203 Total reward: 17.0 Training loss: 4.9124 Explore P: 0.7030\n",
            "Episode: 204 Total reward: 13.0 Training loss: 5.4342 Explore P: 0.7021\n",
            "Episode: 205 Total reward: 11.0 Training loss: 6.2914 Explore P: 0.7013\n",
            "Episode: 206 Total reward: 10.0 Training loss: 5.7735 Explore P: 0.7006\n",
            "Episode: 207 Total reward: 16.0 Training loss: 6.0718 Explore P: 0.6995\n",
            "Episode: 208 Total reward: 13.0 Training loss: 4.1866 Explore P: 0.6986\n",
            "Episode: 209 Total reward: 13.0 Training loss: 5.1275 Explore P: 0.6977\n",
            "Episode: 210 Total reward: 8.0 Training loss: 94.4254 Explore P: 0.6972\n",
            "Episode: 211 Total reward: 10.0 Training loss: 108.7854 Explore P: 0.6965\n",
            "Episode: 212 Total reward: 8.0 Training loss: 144.7997 Explore P: 0.6960\n",
            "Episode: 213 Total reward: 13.0 Training loss: 155.3517 Explore P: 0.6951\n",
            "Episode: 214 Total reward: 12.0 Training loss: 122.0916 Explore P: 0.6942\n",
            "Episode: 215 Total reward: 15.0 Training loss: 63.2665 Explore P: 0.6932\n",
            "Episode: 216 Total reward: 12.0 Training loss: 42.7084 Explore P: 0.6924\n",
            "Episode: 217 Total reward: 9.0 Training loss: 68.4491 Explore P: 0.6918\n",
            "Episode: 218 Total reward: 19.0 Training loss: 73.8484 Explore P: 0.6905\n",
            "Episode: 219 Total reward: 23.0 Training loss: 77.9190 Explore P: 0.6889\n",
            "Episode: 220 Total reward: 15.0 Training loss: 5.3023 Explore P: 0.6879\n",
            "Episode: 221 Total reward: 24.0 Training loss: 103.7962 Explore P: 0.6863\n",
            "Episode: 222 Total reward: 14.0 Training loss: 47.2777 Explore P: 0.6853\n",
            "Episode: 223 Total reward: 24.0 Training loss: 43.8399 Explore P: 0.6837\n",
            "Episode: 224 Total reward: 24.0 Training loss: 51.8741 Explore P: 0.6821\n",
            "Episode: 225 Total reward: 24.0 Training loss: 28.7221 Explore P: 0.6805\n",
            "Episode: 226 Total reward: 13.0 Training loss: 61.1546 Explore P: 0.6796\n",
            "Episode: 227 Total reward: 9.0 Training loss: 42.1040 Explore P: 0.6790\n",
            "Episode: 228 Total reward: 9.0 Training loss: 5.1898 Explore P: 0.6784\n",
            "Episode: 229 Total reward: 19.0 Training loss: 45.3153 Explore P: 0.6771\n",
            "Episode: 230 Total reward: 14.0 Training loss: 58.0574 Explore P: 0.6762\n",
            "Episode: 231 Total reward: 16.0 Training loss: 4.1648 Explore P: 0.6751\n",
            "Episode: 232 Total reward: 9.0 Training loss: 32.6488 Explore P: 0.6745\n",
            "Episode: 233 Total reward: 9.0 Training loss: 4.4224 Explore P: 0.6739\n",
            "Episode: 234 Total reward: 15.0 Training loss: 83.1813 Explore P: 0.6730\n",
            "Episode: 235 Total reward: 23.0 Training loss: 46.5299 Explore P: 0.6714\n",
            "Episode: 236 Total reward: 15.0 Training loss: 73.9608 Explore P: 0.6704\n",
            "Episode: 237 Total reward: 58.0 Training loss: 43.5319 Explore P: 0.6666\n",
            "Episode: 238 Total reward: 10.0 Training loss: 25.5718 Explore P: 0.6660\n",
            "Episode: 239 Total reward: 13.0 Training loss: 3.0081 Explore P: 0.6651\n",
            "Episode: 240 Total reward: 25.0 Training loss: 83.0614 Explore P: 0.6635\n",
            "Episode: 241 Total reward: 11.0 Training loss: 66.2694 Explore P: 0.6628\n",
            "Episode: 242 Total reward: 31.0 Training loss: 44.5409 Explore P: 0.6607\n",
            "Episode: 243 Total reward: 11.0 Training loss: 22.4662 Explore P: 0.6600\n",
            "Episode: 244 Total reward: 16.0 Training loss: 71.9392 Explore P: 0.6590\n",
            "Episode: 245 Total reward: 17.0 Training loss: 60.9605 Explore P: 0.6579\n",
            "Episode: 246 Total reward: 21.0 Training loss: 51.2703 Explore P: 0.6565\n",
            "Episode: 247 Total reward: 10.0 Training loss: 71.7031 Explore P: 0.6559\n",
            "Episode: 248 Total reward: 20.0 Training loss: 20.5148 Explore P: 0.6546\n",
            "Episode: 249 Total reward: 28.0 Training loss: 57.4285 Explore P: 0.6528\n",
            "Episode: 250 Total reward: 11.0 Training loss: 2.0375 Explore P: 0.6521\n",
            "Episode: 251 Total reward: 7.0 Training loss: 26.6661 Explore P: 0.6516\n",
            "Episode: 252 Total reward: 20.0 Training loss: 21.1137 Explore P: 0.6503\n",
            "Episode: 253 Total reward: 16.0 Training loss: 25.3510 Explore P: 0.6493\n",
            "Episode: 254 Total reward: 12.0 Training loss: 21.4096 Explore P: 0.6486\n",
            "Episode: 255 Total reward: 29.0 Training loss: 20.3064 Explore P: 0.6467\n",
            "Episode: 256 Total reward: 15.0 Training loss: 2.1213 Explore P: 0.6457\n",
            "Episode: 257 Total reward: 10.0 Training loss: 27.5442 Explore P: 0.6451\n",
            "Episode: 258 Total reward: 24.0 Training loss: 25.4802 Explore P: 0.6436\n",
            "Episode: 259 Total reward: 10.0 Training loss: 43.9082 Explore P: 0.6430\n",
            "Episode: 260 Total reward: 12.0 Training loss: 56.0040 Explore P: 0.6422\n",
            "Episode: 261 Total reward: 13.0 Training loss: 87.1095 Explore P: 0.6414\n",
            "Episode: 262 Total reward: 11.0 Training loss: 55.0172 Explore P: 0.6407\n",
            "Episode: 263 Total reward: 13.0 Training loss: 28.0570 Explore P: 0.6399\n",
            "Episode: 264 Total reward: 11.0 Training loss: 27.8365 Explore P: 0.6392\n",
            "Episode: 265 Total reward: 19.0 Training loss: 144.3832 Explore P: 0.6380\n",
            "Episode: 266 Total reward: 17.0 Training loss: 17.2170 Explore P: 0.6369\n",
            "Episode: 267 Total reward: 8.0 Training loss: 3.0439 Explore P: 0.6364\n",
            "Episode: 268 Total reward: 8.0 Training loss: 45.6568 Explore P: 0.6359\n",
            "Episode: 269 Total reward: 15.0 Training loss: 23.3475 Explore P: 0.6350\n",
            "Episode: 270 Total reward: 17.0 Training loss: 21.9747 Explore P: 0.6339\n",
            "Episode: 271 Total reward: 7.0 Training loss: 24.1633 Explore P: 0.6335\n",
            "Episode: 272 Total reward: 14.0 Training loss: 65.5336 Explore P: 0.6326\n",
            "Episode: 273 Total reward: 12.0 Training loss: 21.7945 Explore P: 0.6319\n",
            "Episode: 274 Total reward: 11.0 Training loss: 80.6000 Explore P: 0.6312\n",
            "Episode: 275 Total reward: 18.0 Training loss: 22.9005 Explore P: 0.6301\n",
            "Episode: 276 Total reward: 8.0 Training loss: 21.7801 Explore P: 0.6296\n",
            "Episode: 277 Total reward: 15.0 Training loss: 20.5480 Explore P: 0.6286\n",
            "Episode: 278 Total reward: 16.0 Training loss: 20.0161 Explore P: 0.6276\n",
            "Episode: 279 Total reward: 9.0 Training loss: 1.9770 Explore P: 0.6271\n",
            "Episode: 280 Total reward: 29.0 Training loss: 1.8537 Explore P: 0.6253\n",
            "Episode: 281 Total reward: 10.0 Training loss: 39.8594 Explore P: 0.6247\n",
            "Episode: 282 Total reward: 37.0 Training loss: 2.1705 Explore P: 0.6224\n",
            "Episode: 283 Total reward: 27.0 Training loss: 18.4664 Explore P: 0.6208\n",
            "Episode: 284 Total reward: 12.0 Training loss: 1.7361 Explore P: 0.6200\n",
            "Episode: 285 Total reward: 17.0 Training loss: 32.7222 Explore P: 0.6190\n",
            "Episode: 286 Total reward: 18.0 Training loss: 16.6778 Explore P: 0.6179\n",
            "Episode: 287 Total reward: 10.0 Training loss: 1.4314 Explore P: 0.6173\n",
            "Episode: 288 Total reward: 31.0 Training loss: 1.4669 Explore P: 0.6154\n",
            "Episode: 289 Total reward: 25.0 Training loss: 0.9560 Explore P: 0.6139\n",
            "Episode: 290 Total reward: 15.0 Training loss: 38.7557 Explore P: 0.6130\n",
            "Episode: 291 Total reward: 23.0 Training loss: 39.0054 Explore P: 0.6116\n",
            "Episode: 292 Total reward: 12.0 Training loss: 40.1010 Explore P: 0.6109\n",
            "Episode: 293 Total reward: 39.0 Training loss: 15.9223 Explore P: 0.6085\n",
            "Episode: 294 Total reward: 18.0 Training loss: 1.2421 Explore P: 0.6075\n",
            "Episode: 295 Total reward: 21.0 Training loss: 31.8607 Explore P: 0.6062\n",
            "Episode: 296 Total reward: 11.0 Training loss: 1.8663 Explore P: 0.6056\n",
            "Episode: 297 Total reward: 19.0 Training loss: 2.2562 Explore P: 0.6044\n",
            "Episode: 298 Total reward: 11.0 Training loss: 13.6949 Explore P: 0.6038\n",
            "Episode: 299 Total reward: 12.0 Training loss: 12.2720 Explore P: 0.6031\n",
            "Episode: 300 Total reward: 16.0 Training loss: 36.0420 Explore P: 0.6021\n",
            "Episode: 301 Total reward: 24.0 Training loss: 15.5471 Explore P: 0.6007\n",
            "Episode: 302 Total reward: 13.0 Training loss: 1.9528 Explore P: 0.5999\n",
            "Episode: 303 Total reward: 28.0 Training loss: 40.9280 Explore P: 0.5983\n",
            "Episode: 304 Total reward: 26.0 Training loss: 35.3187 Explore P: 0.5968\n",
            "Episode: 305 Total reward: 17.0 Training loss: 16.5967 Explore P: 0.5958\n",
            "Episode: 306 Total reward: 15.0 Training loss: 15.6865 Explore P: 0.5949\n",
            "Episode: 307 Total reward: 16.0 Training loss: 22.2747 Explore P: 0.5939\n",
            "Episode: 308 Total reward: 12.0 Training loss: 20.8787 Explore P: 0.5932\n",
            "Episode: 309 Total reward: 29.0 Training loss: 2.0837 Explore P: 0.5916\n",
            "Episode: 310 Total reward: 30.0 Training loss: 20.8666 Explore P: 0.5898\n",
            "Episode: 311 Total reward: 21.0 Training loss: 22.8394 Explore P: 0.5886\n",
            "Episode: 312 Total reward: 12.0 Training loss: 2.1596 Explore P: 0.5879\n",
            "Episode: 313 Total reward: 17.0 Training loss: 33.9270 Explore P: 0.5869\n",
            "Episode: 314 Total reward: 17.0 Training loss: 39.8194 Explore P: 0.5859\n",
            "Episode: 315 Total reward: 41.0 Training loss: 2.2787 Explore P: 0.5836\n",
            "Episode: 316 Total reward: 16.0 Training loss: 26.1677 Explore P: 0.5827\n",
            "Episode: 317 Total reward: 17.0 Training loss: 14.6427 Explore P: 0.5817\n",
            "Episode: 318 Total reward: 24.0 Training loss: 13.1102 Explore P: 0.5803\n",
            "Episode: 319 Total reward: 85.0 Training loss: 23.9191 Explore P: 0.5755\n",
            "Episode: 320 Total reward: 29.0 Training loss: 13.2063 Explore P: 0.5739\n",
            "Episode: 321 Total reward: 26.0 Training loss: 23.0732 Explore P: 0.5724\n",
            "Episode: 322 Total reward: 18.0 Training loss: 11.8685 Explore P: 0.5714\n",
            "Episode: 323 Total reward: 33.0 Training loss: 8.8136 Explore P: 0.5695\n",
            "Episode: 324 Total reward: 13.0 Training loss: 18.7973 Explore P: 0.5688\n",
            "Episode: 325 Total reward: 21.0 Training loss: 45.4726 Explore P: 0.5676\n",
            "Episode: 326 Total reward: 29.0 Training loss: 15.4521 Explore P: 0.5660\n",
            "Episode: 327 Total reward: 28.0 Training loss: 1.9669 Explore P: 0.5645\n",
            "Episode: 328 Total reward: 23.0 Training loss: 23.3759 Explore P: 0.5632\n",
            "Episode: 329 Total reward: 15.0 Training loss: 8.4632 Explore P: 0.5624\n",
            "Episode: 330 Total reward: 18.0 Training loss: 39.0448 Explore P: 0.5614\n",
            "Episode: 331 Total reward: 14.0 Training loss: 13.9831 Explore P: 0.5606\n",
            "Episode: 332 Total reward: 19.0 Training loss: 13.4293 Explore P: 0.5596\n",
            "Episode: 333 Total reward: 21.0 Training loss: 1.4464 Explore P: 0.5584\n",
            "Episode: 334 Total reward: 29.0 Training loss: 1.9249 Explore P: 0.5568\n",
            "Episode: 335 Total reward: 30.0 Training loss: 17.7598 Explore P: 0.5552\n",
            "Episode: 336 Total reward: 42.0 Training loss: 9.0277 Explore P: 0.5529\n",
            "Episode: 337 Total reward: 38.0 Training loss: 23.4645 Explore P: 0.5508\n",
            "Episode: 338 Total reward: 22.0 Training loss: 3.1311 Explore P: 0.5496\n",
            "Episode: 339 Total reward: 21.0 Training loss: 10.4734 Explore P: 0.5485\n",
            "Episode: 340 Total reward: 25.0 Training loss: 1.2067 Explore P: 0.5472\n",
            "Episode: 341 Total reward: 38.0 Training loss: 29.1540 Explore P: 0.5451\n",
            "Episode: 342 Total reward: 19.0 Training loss: 11.6974 Explore P: 0.5441\n",
            "Episode: 343 Total reward: 23.0 Training loss: 24.2332 Explore P: 0.5429\n",
            "Episode: 344 Total reward: 21.0 Training loss: 2.3541 Explore P: 0.5418\n",
            "Episode: 345 Total reward: 36.0 Training loss: 7.1773 Explore P: 0.5399\n",
            "Episode: 346 Total reward: 62.0 Training loss: 1.6588 Explore P: 0.5366\n",
            "Episode: 347 Total reward: 14.0 Training loss: 2.6897 Explore P: 0.5358\n",
            "Episode: 348 Total reward: 153.0 Training loss: 25.3424 Explore P: 0.5279\n",
            "Episode: 349 Total reward: 47.0 Training loss: 17.3446 Explore P: 0.5254\n",
            "Episode: 350 Total reward: 22.0 Training loss: 33.5119 Explore P: 0.5243\n",
            "Episode: 351 Total reward: 56.0 Training loss: 2.4050 Explore P: 0.5214\n",
            "Episode: 352 Total reward: 70.0 Training loss: 11.1588 Explore P: 0.5179\n",
            "Episode: 353 Total reward: 28.0 Training loss: 17.8642 Explore P: 0.5164\n",
            "Episode: 354 Total reward: 25.0 Training loss: 38.7784 Explore P: 0.5152\n",
            "Episode: 355 Total reward: 51.0 Training loss: 1.1269 Explore P: 0.5126\n",
            "Episode: 356 Total reward: 104.0 Training loss: 3.5198 Explore P: 0.5074\n",
            "Episode: 357 Total reward: 53.0 Training loss: 3.3171 Explore P: 0.5048\n",
            "Episode: 358 Total reward: 64.0 Training loss: 6.9340 Explore P: 0.5016\n",
            "Episode: 359 Total reward: 66.0 Training loss: 15.8233 Explore P: 0.4984\n",
            "Episode: 360 Total reward: 59.0 Training loss: 26.4688 Explore P: 0.4955\n",
            "Episode: 361 Total reward: 68.0 Training loss: 42.5061 Explore P: 0.4922\n",
            "Episode: 362 Total reward: 81.0 Training loss: 35.0905 Explore P: 0.4883\n",
            "Episode: 363 Total reward: 30.0 Training loss: 11.4336 Explore P: 0.4869\n",
            "Episode: 364 Total reward: 36.0 Training loss: 1.8700 Explore P: 0.4852\n",
            "Episode: 365 Total reward: 70.0 Training loss: 2.2948 Explore P: 0.4819\n",
            "Episode: 366 Total reward: 62.0 Training loss: 43.3063 Explore P: 0.4790\n",
            "Episode: 367 Total reward: 52.0 Training loss: 23.4770 Explore P: 0.4765\n",
            "Episode: 368 Total reward: 18.0 Training loss: 15.5351 Explore P: 0.4757\n",
            "Episode: 369 Total reward: 30.0 Training loss: 1.8502 Explore P: 0.4743\n",
            "Episode: 370 Total reward: 99.0 Training loss: 3.1256 Explore P: 0.4697\n",
            "Episode: 371 Total reward: 52.0 Training loss: 104.5490 Explore P: 0.4673\n",
            "Episode: 372 Total reward: 29.0 Training loss: 2.3684 Explore P: 0.4660\n",
            "Episode: 373 Total reward: 53.0 Training loss: 2.5670 Explore P: 0.4636\n",
            "Episode: 374 Total reward: 42.0 Training loss: 18.5278 Explore P: 0.4617\n",
            "Episode: 375 Total reward: 77.0 Training loss: 27.9107 Explore P: 0.4582\n",
            "Episode: 376 Total reward: 37.0 Training loss: 25.1336 Explore P: 0.4566\n",
            "Episode: 377 Total reward: 45.0 Training loss: 24.4627 Explore P: 0.4546\n",
            "Episode: 378 Total reward: 49.0 Training loss: 36.4731 Explore P: 0.4524\n",
            "Episode: 379 Total reward: 73.0 Training loss: 2.5433 Explore P: 0.4492\n",
            "Episode: 380 Total reward: 61.0 Training loss: 15.7388 Explore P: 0.4465\n",
            "Episode: 381 Total reward: 73.0 Training loss: 1.7408 Explore P: 0.4433\n",
            "Episode: 382 Total reward: 137.0 Training loss: 42.9901 Explore P: 0.4374\n",
            "Episode: 383 Total reward: 15.0 Training loss: 4.7167 Explore P: 0.4368\n",
            "Episode: 384 Total reward: 45.0 Training loss: 34.9440 Explore P: 0.4349\n",
            "Episode: 385 Total reward: 19.0 Training loss: 4.2069 Explore P: 0.4341\n",
            "Episode: 386 Total reward: 75.0 Training loss: 34.7819 Explore P: 0.4309\n",
            "Episode: 387 Total reward: 35.0 Training loss: 27.2684 Explore P: 0.4294\n",
            "Episode: 388 Total reward: 46.0 Training loss: 5.3543 Explore P: 0.4275\n",
            "Episode: 389 Total reward: 51.0 Training loss: 61.7276 Explore P: 0.4254\n",
            "Episode: 390 Total reward: 43.0 Training loss: 2.4802 Explore P: 0.4236\n",
            "Episode: 391 Total reward: 64.0 Training loss: 91.5664 Explore P: 0.4210\n",
            "Episode: 392 Total reward: 63.0 Training loss: 2.0299 Explore P: 0.4184\n",
            "Episode: 393 Total reward: 18.0 Training loss: 18.3269 Explore P: 0.4176\n",
            "Episode: 394 Total reward: 26.0 Training loss: 35.7114 Explore P: 0.4166\n",
            "Episode: 395 Total reward: 34.0 Training loss: 21.5861 Explore P: 0.4152\n",
            "Episode: 396 Total reward: 40.0 Training loss: 50.0118 Explore P: 0.4136\n",
            "Episode: 397 Total reward: 29.0 Training loss: 69.2395 Explore P: 0.4124\n",
            "Episode: 398 Total reward: 40.0 Training loss: 4.9421 Explore P: 0.4108\n",
            "Episode: 399 Total reward: 44.0 Training loss: 58.4571 Explore P: 0.4091\n",
            "Episode: 400 Total reward: 93.0 Training loss: 22.4096 Explore P: 0.4054\n",
            "Episode: 401 Total reward: 33.0 Training loss: 4.1816 Explore P: 0.4041\n",
            "Episode: 402 Total reward: 73.0 Training loss: 19.1812 Explore P: 0.4012\n",
            "Episode: 403 Total reward: 35.0 Training loss: 4.9024 Explore P: 0.3998\n",
            "Episode: 404 Total reward: 32.0 Training loss: 3.7833 Explore P: 0.3986\n",
            "Episode: 405 Total reward: 107.0 Training loss: 12.6324 Explore P: 0.3944\n",
            "Episode: 406 Total reward: 36.0 Training loss: 2.8132 Explore P: 0.3931\n",
            "Episode: 407 Total reward: 37.0 Training loss: 31.6395 Explore P: 0.3917\n",
            "Episode: 408 Total reward: 88.0 Training loss: 8.7914 Explore P: 0.3883\n",
            "Episode: 409 Total reward: 47.0 Training loss: 30.8483 Explore P: 0.3865\n",
            "Episode: 410 Total reward: 45.0 Training loss: 17.6962 Explore P: 0.3848\n",
            "Episode: 411 Total reward: 128.0 Training loss: 4.3055 Explore P: 0.3801\n",
            "Episode: 412 Total reward: 140.0 Training loss: 27.0121 Explore P: 0.3749\n",
            "Episode: 413 Total reward: 81.0 Training loss: 3.5059 Explore P: 0.3720\n",
            "Episode: 414 Total reward: 70.0 Training loss: 4.2233 Explore P: 0.3695\n",
            "Episode: 415 Total reward: 70.0 Training loss: 89.5230 Explore P: 0.3670\n",
            "Episode: 416 Total reward: 53.0 Training loss: 2.5169 Explore P: 0.3651\n",
            "Episode: 417 Total reward: 58.0 Training loss: 3.8065 Explore P: 0.3630\n",
            "Episode: 418 Total reward: 45.0 Training loss: 10.9584 Explore P: 0.3614\n",
            "Episode: 419 Total reward: 62.0 Training loss: 4.9634 Explore P: 0.3593\n",
            "Episode: 420 Total reward: 29.0 Training loss: 270.3622 Explore P: 0.3582\n",
            "Episode: 421 Total reward: 33.0 Training loss: 7.1830 Explore P: 0.3571\n",
            "Episode: 422 Total reward: 38.0 Training loss: 57.7764 Explore P: 0.3558\n",
            "Episode: 423 Total reward: 31.0 Training loss: 46.0924 Explore P: 0.3547\n",
            "Episode: 424 Total reward: 30.0 Training loss: 3.7743 Explore P: 0.3537\n",
            "Episode: 425 Total reward: 50.0 Training loss: 5.0960 Explore P: 0.3520\n",
            "Episode: 426 Total reward: 61.0 Training loss: 5.9673 Explore P: 0.3499\n",
            "Episode: 427 Total reward: 34.0 Training loss: 36.7790 Explore P: 0.3487\n",
            "Episode: 428 Total reward: 71.0 Training loss: 55.8686 Explore P: 0.3463\n",
            "Episode: 429 Total reward: 62.0 Training loss: 3.5530 Explore P: 0.3443\n",
            "Episode: 430 Total reward: 27.0 Training loss: 4.7381 Explore P: 0.3434\n",
            "Episode: 431 Total reward: 34.0 Training loss: 2.7881 Explore P: 0.3422\n",
            "Episode: 432 Total reward: 58.0 Training loss: 3.3380 Explore P: 0.3403\n",
            "Episode: 433 Total reward: 77.0 Training loss: 4.9029 Explore P: 0.3378\n",
            "Episode: 434 Total reward: 73.0 Training loss: 2.5825 Explore P: 0.3354\n",
            "Episode: 435 Total reward: 29.0 Training loss: 21.1726 Explore P: 0.3344\n",
            "Episode: 436 Total reward: 44.0 Training loss: 16.9987 Explore P: 0.3330\n",
            "Episode: 437 Total reward: 55.0 Training loss: 2.2718 Explore P: 0.3312\n",
            "Episode: 438 Total reward: 19.0 Training loss: 73.9321 Explore P: 0.3306\n",
            "Episode: 439 Total reward: 44.0 Training loss: 3.3021 Explore P: 0.3292\n",
            "Episode: 440 Total reward: 45.0 Training loss: 2.3234 Explore P: 0.3278\n",
            "Episode: 441 Total reward: 35.0 Training loss: 12.0087 Explore P: 0.3267\n",
            "Episode: 442 Total reward: 73.0 Training loss: 2.5290 Explore P: 0.3244\n",
            "Episode: 443 Total reward: 41.0 Training loss: 4.1312 Explore P: 0.3231\n",
            "Episode: 444 Total reward: 35.0 Training loss: 78.2815 Explore P: 0.3220\n",
            "Episode: 445 Total reward: 40.0 Training loss: 3.8405 Explore P: 0.3208\n",
            "Episode: 446 Total reward: 39.0 Training loss: 1.8360 Explore P: 0.3195\n",
            "Episode: 447 Total reward: 38.0 Training loss: 3.1462 Explore P: 0.3184\n",
            "Episode: 448 Total reward: 71.0 Training loss: 143.7237 Explore P: 0.3162\n",
            "Episode: 449 Total reward: 33.0 Training loss: 2.0188 Explore P: 0.3152\n",
            "Episode: 450 Total reward: 75.0 Training loss: 79.6796 Explore P: 0.3129\n",
            "Episode: 451 Total reward: 51.0 Training loss: 6.2493 Explore P: 0.3114\n",
            "Episode: 452 Total reward: 36.0 Training loss: 7.1155 Explore P: 0.3103\n",
            "Episode: 453 Total reward: 46.0 Training loss: 76.6247 Explore P: 0.3089\n",
            "Episode: 454 Total reward: 38.0 Training loss: 190.5215 Explore P: 0.3078\n",
            "Episode: 455 Total reward: 57.0 Training loss: 22.5659 Explore P: 0.3061\n",
            "Episode: 456 Total reward: 85.0 Training loss: 54.8292 Explore P: 0.3036\n",
            "Episode: 457 Total reward: 44.0 Training loss: 4.6159 Explore P: 0.3023\n",
            "Episode: 458 Total reward: 153.0 Training loss: 70.8149 Explore P: 0.2978\n",
            "Episode: 459 Total reward: 39.0 Training loss: 3.1352 Explore P: 0.2967\n",
            "Episode: 460 Total reward: 47.0 Training loss: 2.7343 Explore P: 0.2954\n",
            "Episode: 461 Total reward: 34.0 Training loss: 184.8423 Explore P: 0.2944\n",
            "Episode: 462 Total reward: 32.0 Training loss: 2.4714 Explore P: 0.2935\n",
            "Episode: 463 Total reward: 55.0 Training loss: 167.0209 Explore P: 0.2919\n",
            "Episode: 464 Total reward: 34.0 Training loss: 5.2794 Explore P: 0.2910\n",
            "Episode: 465 Total reward: 112.0 Training loss: 2.3856 Explore P: 0.2879\n",
            "Episode: 466 Total reward: 79.0 Training loss: 71.5836 Explore P: 0.2857\n",
            "Episode: 467 Total reward: 61.0 Training loss: 3.3785 Explore P: 0.2840\n",
            "Episode: 468 Total reward: 57.0 Training loss: 4.0262 Explore P: 0.2824\n",
            "Episode: 469 Total reward: 37.0 Training loss: 3.8072 Explore P: 0.2814\n",
            "Episode: 470 Total reward: 72.0 Training loss: 2.6100 Explore P: 0.2795\n",
            "Episode: 471 Total reward: 45.0 Training loss: 2.7155 Explore P: 0.2783\n",
            "Episode: 472 Total reward: 43.0 Training loss: 4.1299 Explore P: 0.2771\n",
            "Episode: 473 Total reward: 81.0 Training loss: 1.1696 Explore P: 0.2750\n",
            "Episode: 474 Total reward: 25.0 Training loss: 2.3354 Explore P: 0.2743\n",
            "Episode: 475 Total reward: 49.0 Training loss: 263.7083 Explore P: 0.2730\n",
            "Episode: 476 Total reward: 60.0 Training loss: 3.4819 Explore P: 0.2714\n",
            "Episode: 477 Total reward: 101.0 Training loss: 65.1974 Explore P: 0.2688\n",
            "Episode: 478 Total reward: 42.0 Training loss: 4.0072 Explore P: 0.2677\n",
            "Episode: 479 Total reward: 36.0 Training loss: 5.0142 Explore P: 0.2668\n",
            "Episode: 480 Total reward: 63.0 Training loss: 72.5178 Explore P: 0.2652\n",
            "Episode: 481 Total reward: 60.0 Training loss: 73.5596 Explore P: 0.2637\n",
            "Episode: 482 Total reward: 92.0 Training loss: 3.4861 Explore P: 0.2613\n",
            "Episode: 483 Total reward: 71.0 Training loss: 3.4184 Explore P: 0.2596\n",
            "Episode: 484 Total reward: 40.0 Training loss: 3.4445 Explore P: 0.2586\n",
            "Episode: 485 Total reward: 42.0 Training loss: 245.5627 Explore P: 0.2575\n",
            "Episode: 486 Total reward: 50.0 Training loss: 2.4535 Explore P: 0.2563\n",
            "Episode: 487 Total reward: 71.0 Training loss: 2.7334 Explore P: 0.2545\n",
            "Episode: 488 Total reward: 43.0 Training loss: 164.5564 Explore P: 0.2535\n",
            "Episode: 489 Total reward: 48.0 Training loss: 2.6248 Explore P: 0.2523\n",
            "Episode: 490 Total reward: 83.0 Training loss: 2.0101 Explore P: 0.2503\n",
            "Episode: 491 Total reward: 73.0 Training loss: 25.6045 Explore P: 0.2486\n",
            "Episode: 492 Total reward: 54.0 Training loss: 52.7274 Explore P: 0.2473\n",
            "Episode: 493 Total reward: 83.0 Training loss: 116.4229 Explore P: 0.2453\n",
            "Episode: 494 Total reward: 51.0 Training loss: 70.4339 Explore P: 0.2441\n",
            "Episode: 495 Total reward: 54.0 Training loss: 2.7349 Explore P: 0.2429\n",
            "Episode: 496 Total reward: 184.0 Training loss: 155.2638 Explore P: 0.2386\n",
            "Episode: 497 Total reward: 40.0 Training loss: 128.0720 Explore P: 0.2377\n",
            "Episode: 498 Total reward: 77.0 Training loss: 107.7104 Explore P: 0.2360\n",
            "Episode: 499 Total reward: 85.0 Training loss: 1.3540 Explore P: 0.2341\n",
            "Episode: 500 Total reward: 62.0 Training loss: 1.9396 Explore P: 0.2327\n",
            "Episode: 501 Total reward: 54.0 Training loss: 2.1487 Explore P: 0.2315\n",
            "Episode: 502 Total reward: 44.0 Training loss: 3.9424 Explore P: 0.2305\n",
            "Episode: 503 Total reward: 39.0 Training loss: 3.1015 Explore P: 0.2296\n",
            "Episode: 504 Total reward: 39.0 Training loss: 1.5481 Explore P: 0.2288\n",
            "Episode: 505 Total reward: 150.0 Training loss: 1.0252 Explore P: 0.2255\n",
            "Episode: 506 Total reward: 48.0 Training loss: 2.1476 Explore P: 0.2245\n",
            "Episode: 507 Total reward: 67.0 Training loss: 3.3558 Explore P: 0.2231\n",
            "Episode: 508 Total reward: 86.0 Training loss: 2.6461 Explore P: 0.2212\n",
            "Episode: 509 Total reward: 63.0 Training loss: 123.3944 Explore P: 0.2199\n",
            "Episode: 510 Total reward: 65.0 Training loss: 72.9654 Explore P: 0.2186\n",
            "Episode: 511 Total reward: 166.0 Training loss: 2.4899 Explore P: 0.2151\n",
            "Episode: 512 Total reward: 91.0 Training loss: 2.0364 Explore P: 0.2133\n",
            "Episode: 513 Total reward: 64.0 Training loss: 228.2437 Explore P: 0.2120\n",
            "Episode: 514 Total reward: 62.0 Training loss: 74.3353 Explore P: 0.2107\n",
            "Episode: 515 Total reward: 110.0 Training loss: 3.9887 Explore P: 0.2085\n",
            "Episode: 516 Total reward: 110.0 Training loss: 2.2885 Explore P: 0.2064\n",
            "Episode: 517 Total reward: 120.0 Training loss: 2.3198 Explore P: 0.2040\n",
            "Episode: 518 Total reward: 72.0 Training loss: 220.3853 Explore P: 0.2026\n",
            "Episode: 519 Total reward: 92.0 Training loss: 1.3490 Explore P: 0.2009\n",
            "Episode: 520 Total reward: 148.0 Training loss: 2.1806 Explore P: 0.1980\n",
            "Episode: 521 Total reward: 55.0 Training loss: 1.3556 Explore P: 0.1970\n",
            "Episode: 522 Total reward: 46.0 Training loss: 1.6734 Explore P: 0.1962\n",
            "Episode: 523 Total reward: 79.0 Training loss: 309.8220 Explore P: 0.1947\n",
            "Episode: 524 Total reward: 56.0 Training loss: 1.6650 Explore P: 0.1937\n",
            "Episode: 525 Total reward: 82.0 Training loss: 1.0236 Explore P: 0.1922\n",
            "Episode: 526 Total reward: 67.0 Training loss: 1.4003 Explore P: 0.1909\n",
            "Episode: 527 Total reward: 91.0 Training loss: 335.1842 Explore P: 0.1893\n",
            "Episode: 528 Total reward: 57.0 Training loss: 2.4446 Explore P: 0.1883\n",
            "Episode: 529 Total reward: 54.0 Training loss: 2.9391 Explore P: 0.1873\n",
            "Episode: 530 Total reward: 79.0 Training loss: 1.7370 Explore P: 0.1859\n",
            "Episode: 531 Total reward: 91.0 Training loss: 0.9909 Explore P: 0.1843\n",
            "Episode: 532 Total reward: 152.0 Training loss: 107.3668 Explore P: 0.1817\n",
            "Episode: 533 Total reward: 115.0 Training loss: 56.1304 Explore P: 0.1797\n",
            "Episode: 534 Total reward: 76.0 Training loss: 2.2403 Explore P: 0.1785\n",
            "Episode: 535 Total reward: 113.0 Training loss: 1.4968 Explore P: 0.1766\n",
            "Episode: 536 Total reward: 94.0 Training loss: 64.4510 Explore P: 0.1750\n",
            "Episode: 537 Total reward: 78.0 Training loss: 176.4753 Explore P: 0.1737\n",
            "Episode: 538 Total reward: 62.0 Training loss: 1.9703 Explore P: 0.1727\n",
            "Episode: 539 Total reward: 52.0 Training loss: 1.7238 Explore P: 0.1719\n",
            "Episode: 540 Total reward: 72.0 Training loss: 117.7318 Explore P: 0.1707\n",
            "Episode: 541 Total reward: 60.0 Training loss: 58.1359 Explore P: 0.1697\n",
            "Episode: 542 Total reward: 101.0 Training loss: 76.1939 Explore P: 0.1681\n",
            "Episode: 543 Total reward: 73.0 Training loss: 1.3721 Explore P: 0.1670\n",
            "Episode: 544 Total reward: 50.0 Training loss: 1.8139 Explore P: 0.1662\n",
            "Episode: 545 Total reward: 102.0 Training loss: 1.3740 Explore P: 0.1646\n",
            "Episode: 546 Total reward: 59.0 Training loss: 2.1339 Explore P: 0.1637\n",
            "Episode: 547 Total reward: 98.0 Training loss: 1.3233 Explore P: 0.1622\n",
            "Episode: 548 Total reward: 81.0 Training loss: 2.1365 Explore P: 0.1610\n",
            "Episode: 549 Total reward: 64.0 Training loss: 1.5236 Explore P: 0.1600\n",
            "Episode: 550 Total reward: 125.0 Training loss: 0.8761 Explore P: 0.1582\n",
            "Episode: 551 Total reward: 95.0 Training loss: 1.4596 Explore P: 0.1568\n",
            "Episode: 552 Total reward: 88.0 Training loss: 1.8805 Explore P: 0.1555\n",
            "Episode: 553 Total reward: 74.0 Training loss: 2.2933 Explore P: 0.1544\n",
            "Episode: 554 Total reward: 81.0 Training loss: 0.9181 Explore P: 0.1532\n",
            "Episode: 555 Total reward: 76.0 Training loss: 1.1165 Explore P: 0.1522\n",
            "Episode: 556 Total reward: 86.0 Training loss: 35.5029 Explore P: 0.1509\n",
            "Episode: 557 Total reward: 127.0 Training loss: 0.9735 Explore P: 0.1492\n",
            "Episode: 558 Total reward: 86.0 Training loss: 1.9729 Explore P: 0.1480\n",
            "Episode: 559 Total reward: 126.0 Training loss: 0.6838 Explore P: 0.1462\n",
            "Episode: 560 Total reward: 106.0 Training loss: 38.7965 Explore P: 0.1448\n",
            "Episode: 561 Total reward: 103.0 Training loss: 1.2950 Explore P: 0.1434\n",
            "Episode: 562 Total reward: 103.0 Training loss: 1.0159 Explore P: 0.1421\n",
            "Episode: 563 Total reward: 110.0 Training loss: 95.4698 Explore P: 0.1406\n",
            "Episode: 564 Total reward: 113.0 Training loss: 0.4484 Explore P: 0.1391\n",
            "Episode: 565 Total reward: 103.0 Training loss: 0.4346 Explore P: 0.1378\n",
            "Episode: 566 Total reward: 137.0 Training loss: 1.2522 Explore P: 0.1361\n",
            "Episode: 567 Total reward: 116.0 Training loss: 0.7685 Explore P: 0.1346\n",
            "Episode: 568 Total reward: 67.0 Training loss: 86.3178 Explore P: 0.1338\n",
            "Episode: 569 Total reward: 153.0 Training loss: 2.0483 Explore P: 0.1319\n",
            "Episode: 570 Total reward: 123.0 Training loss: 1.0195 Explore P: 0.1304\n",
            "Episode: 571 Total reward: 157.0 Training loss: 1.4853 Explore P: 0.1285\n",
            "Episode: 572 Total reward: 154.0 Training loss: 0.8391 Explore P: 0.1267\n",
            "Episode: 573 Total reward: 83.0 Training loss: 43.1048 Explore P: 0.1258\n",
            "Episode: 574 Total reward: 171.0 Training loss: 1.3328 Explore P: 0.1238\n",
            "Episode: 575 Total reward: 160.0 Training loss: 0.7568 Explore P: 0.1220\n",
            "Episode: 576 Total reward: 199.0 Training loss: 0.9807 Explore P: 0.1198\n",
            "Episode: 577 Total reward: 199.0 Training loss: 0.9200 Explore P: 0.1176\n",
            "Episode: 578 Total reward: 165.0 Training loss: 1.2187 Explore P: 0.1159\n",
            "Episode: 579 Total reward: 174.0 Training loss: 1.0765 Explore P: 0.1140\n",
            "Episode: 580 Total reward: 149.0 Training loss: 0.6441 Explore P: 0.1125\n",
            "Episode: 581 Total reward: 183.0 Training loss: 0.3360 Explore P: 0.1106\n",
            "Episode: 582 Total reward: 189.0 Training loss: 34.2668 Explore P: 0.1088\n",
            "Episode: 583 Total reward: 143.0 Training loss: 1.5104 Explore P: 0.1074\n",
            "Episode: 584 Total reward: 199.0 Training loss: 1.0514 Explore P: 0.1054\n",
            "Episode: 585 Total reward: 166.0 Training loss: 0.7188 Explore P: 0.1039\n",
            "Episode: 586 Total reward: 195.0 Training loss: 0.9788 Explore P: 0.1021\n",
            "Episode: 587 Total reward: 198.0 Training loss: 1.5955 Explore P: 0.1003\n",
            "Episode: 588 Total reward: 164.0 Training loss: 1.4116 Explore P: 0.0988\n",
            "Episode: 589 Total reward: 130.0 Training loss: 0.8292 Explore P: 0.0976\n",
            "Episode: 590 Total reward: 167.0 Training loss: 0.6583 Explore P: 0.0962\n",
            "Episode: 591 Total reward: 105.0 Training loss: 1.6326 Explore P: 0.0953\n",
            "Episode: 592 Total reward: 199.0 Training loss: 1.6191 Explore P: 0.0936\n",
            "Episode: 593 Total reward: 179.0 Training loss: 1.6849 Explore P: 0.0921\n",
            "Episode: 594 Total reward: 184.0 Training loss: 1.4757 Explore P: 0.0906\n",
            "Episode: 595 Total reward: 175.0 Training loss: 2.3975 Explore P: 0.0892\n",
            "Episode: 596 Total reward: 199.0 Training loss: 1.1490 Explore P: 0.0877\n",
            "Episode: 597 Total reward: 199.0 Training loss: 87.1754 Explore P: 0.0861\n",
            "Episode: 598 Total reward: 199.0 Training loss: 76.9889 Explore P: 0.0846\n",
            "Episode: 599 Total reward: 191.0 Training loss: 95.8721 Explore P: 0.0832\n",
            "Episode: 600 Total reward: 181.0 Training loss: 0.4308 Explore P: 0.0819\n",
            "Episode: 601 Total reward: 199.0 Training loss: 79.8818 Explore P: 0.0805\n",
            "Episode: 602 Total reward: 159.0 Training loss: 0.8758 Explore P: 0.0794\n",
            "Episode: 603 Total reward: 190.0 Training loss: 1.0128 Explore P: 0.0781\n",
            "Episode: 604 Total reward: 185.0 Training loss: 0.3633 Explore P: 0.0768\n",
            "Episode: 605 Total reward: 188.0 Training loss: 1.2284 Explore P: 0.0756\n",
            "Episode: 606 Total reward: 156.0 Training loss: 0.6950 Explore P: 0.0746\n",
            "Episode: 607 Total reward: 199.0 Training loss: 0.6362 Explore P: 0.0733\n",
            "Episode: 608 Total reward: 178.0 Training loss: 0.9325 Explore P: 0.0722\n",
            "Episode: 609 Total reward: 191.0 Training loss: 0.4813 Explore P: 0.0710\n",
            "Episode: 610 Total reward: 183.0 Training loss: 0.4117 Explore P: 0.0699\n",
            "Episode: 611 Total reward: 190.0 Training loss: 1.3353 Explore P: 0.0688\n",
            "Episode: 612 Total reward: 199.0 Training loss: 0.6476 Explore P: 0.0676\n",
            "Episode: 613 Total reward: 184.0 Training loss: 0.3552 Explore P: 0.0666\n",
            "Episode: 614 Total reward: 199.0 Training loss: 0.3347 Explore P: 0.0654\n",
            "Episode: 615 Total reward: 161.0 Training loss: 0.7470 Explore P: 0.0646\n",
            "Episode: 616 Total reward: 162.0 Training loss: 0.3383 Explore P: 0.0637\n",
            "Episode: 617 Total reward: 161.0 Training loss: 0.7399 Explore P: 0.0628\n",
            "Episode: 618 Total reward: 199.0 Training loss: 1.1899 Explore P: 0.0618\n",
            "Episode: 619 Total reward: 162.0 Training loss: 0.3537 Explore P: 0.0610\n",
            "Episode: 620 Total reward: 199.0 Training loss: 0.1211 Explore P: 0.0599\n",
            "Episode: 621 Total reward: 181.0 Training loss: 0.6225 Explore P: 0.0591\n",
            "Episode: 622 Total reward: 152.0 Training loss: 0.2583 Explore P: 0.0583\n",
            "Episode: 623 Total reward: 148.0 Training loss: 0.2828 Explore P: 0.0576\n",
            "Episode: 624 Total reward: 199.0 Training loss: 0.4796 Explore P: 0.0567\n",
            "Episode: 625 Total reward: 149.0 Training loss: 19.9477 Explore P: 0.0560\n",
            "Episode: 626 Total reward: 156.0 Training loss: 0.2755 Explore P: 0.0553\n",
            "Episode: 627 Total reward: 180.0 Training loss: 0.3186 Explore P: 0.0545\n",
            "Episode: 628 Total reward: 139.0 Training loss: 0.2207 Explore P: 0.0538\n",
            "Episode: 629 Total reward: 147.0 Training loss: 0.3493 Explore P: 0.0532\n",
            "Episode: 630 Total reward: 139.0 Training loss: 0.3309 Explore P: 0.0526\n",
            "Episode: 631 Total reward: 169.0 Training loss: 0.3682 Explore P: 0.0519\n",
            "Episode: 632 Total reward: 151.0 Training loss: 0.5408 Explore P: 0.0513\n",
            "Episode: 633 Total reward: 132.0 Training loss: 0.4795 Explore P: 0.0507\n",
            "Episode: 634 Total reward: 146.0 Training loss: 0.4190 Explore P: 0.0501\n",
            "Episode: 635 Total reward: 130.0 Training loss: 0.5915 Explore P: 0.0496\n",
            "Episode: 636 Total reward: 143.0 Training loss: 0.3754 Explore P: 0.0491\n",
            "Episode: 637 Total reward: 161.0 Training loss: 0.2275 Explore P: 0.0484\n",
            "Episode: 638 Total reward: 152.0 Training loss: 0.5547 Explore P: 0.0478\n",
            "Episode: 639 Total reward: 134.0 Training loss: 0.5672 Explore P: 0.0473\n",
            "Episode: 640 Total reward: 128.0 Training loss: 1.1722 Explore P: 0.0469\n",
            "Episode: 641 Total reward: 157.0 Training loss: 230.4453 Explore P: 0.0463\n",
            "Episode: 642 Total reward: 142.0 Training loss: 1.2119 Explore P: 0.0458\n",
            "Episode: 643 Total reward: 178.0 Training loss: 6.3107 Explore P: 0.0452\n",
            "Episode: 644 Total reward: 126.0 Training loss: 0.2448 Explore P: 0.0447\n",
            "Episode: 645 Total reward: 158.0 Training loss: 0.4590 Explore P: 0.0442\n",
            "Episode: 646 Total reward: 176.0 Training loss: 0.3993 Explore P: 0.0436\n",
            "Episode: 647 Total reward: 143.0 Training loss: 0.6859 Explore P: 0.0431\n",
            "Episode: 648 Total reward: 142.0 Training loss: 0.3825 Explore P: 0.0426\n",
            "Episode: 649 Total reward: 140.0 Training loss: 0.4301 Explore P: 0.0422\n",
            "Episode: 650 Total reward: 143.0 Training loss: 0.3591 Explore P: 0.0417\n",
            "Episode: 651 Total reward: 199.0 Training loss: 1.8953 Explore P: 0.0411\n",
            "Episode: 652 Total reward: 149.0 Training loss: 0.4172 Explore P: 0.0406\n",
            "Episode: 653 Total reward: 194.0 Training loss: 0.7827 Explore P: 0.0400\n",
            "Episode: 654 Total reward: 162.0 Training loss: 0.3256 Explore P: 0.0396\n",
            "Episode: 655 Total reward: 199.0 Training loss: 0.2811 Explore P: 0.0390\n",
            "Episode: 656 Total reward: 199.0 Training loss: 0.6976 Explore P: 0.0384\n",
            "Episode: 657 Total reward: 199.0 Training loss: 10.4497 Explore P: 0.0378\n",
            "Episode: 658 Total reward: 199.0 Training loss: 22.2708 Explore P: 0.0373\n",
            "Episode: 659 Total reward: 199.0 Training loss: 0.3091 Explore P: 0.0368\n",
            "Episode: 660 Total reward: 192.0 Training loss: 0.3338 Explore P: 0.0363\n",
            "Episode: 661 Total reward: 199.0 Training loss: 0.4075 Explore P: 0.0357\n",
            "Episode: 662 Total reward: 180.0 Training loss: 0.3637 Explore P: 0.0353\n",
            "Episode: 663 Total reward: 199.0 Training loss: 0.2925 Explore P: 0.0348\n",
            "Episode: 664 Total reward: 199.0 Training loss: 0.2026 Explore P: 0.0343\n",
            "Episode: 665 Total reward: 185.0 Training loss: 0.3750 Explore P: 0.0338\n",
            "Episode: 666 Total reward: 199.0 Training loss: 0.2864 Explore P: 0.0334\n",
            "Episode: 667 Total reward: 199.0 Training loss: 0.7198 Explore P: 0.0329\n",
            "Episode: 668 Total reward: 199.0 Training loss: 0.2553 Explore P: 0.0325\n",
            "Episode: 669 Total reward: 197.0 Training loss: 36.1690 Explore P: 0.0320\n",
            "Episode: 670 Total reward: 199.0 Training loss: 442.1289 Explore P: 0.0316\n",
            "Episode: 671 Total reward: 190.0 Training loss: 0.2335 Explore P: 0.0312\n",
            "Episode: 672 Total reward: 199.0 Training loss: 0.2841 Explore P: 0.0308\n",
            "Episode: 673 Total reward: 199.0 Training loss: 0.2960 Explore P: 0.0304\n",
            "Episode: 674 Total reward: 182.0 Training loss: 0.6313 Explore P: 0.0300\n",
            "Episode: 675 Total reward: 188.0 Training loss: 71.6952 Explore P: 0.0296\n",
            "Episode: 676 Total reward: 190.0 Training loss: 0.3234 Explore P: 0.0292\n",
            "Episode: 677 Total reward: 194.0 Training loss: 43.9770 Explore P: 0.0289\n",
            "Episode: 678 Total reward: 199.0 Training loss: 107.4007 Explore P: 0.0285\n",
            "Episode: 679 Total reward: 199.0 Training loss: 393.1369 Explore P: 0.0281\n",
            "Episode: 680 Total reward: 199.0 Training loss: 20.7286 Explore P: 0.0278\n",
            "Episode: 681 Total reward: 199.0 Training loss: 0.3506 Explore P: 0.0274\n",
            "Episode: 682 Total reward: 199.0 Training loss: 1.6070 Explore P: 0.0271\n",
            "Episode: 683 Total reward: 199.0 Training loss: 0.2330 Explore P: 0.0268\n",
            "Episode: 684 Total reward: 198.0 Training loss: 0.3004 Explore P: 0.0264\n",
            "Episode: 685 Total reward: 199.0 Training loss: 0.4724 Explore P: 0.0261\n",
            "Episode: 686 Total reward: 188.0 Training loss: 0.2305 Explore P: 0.0258\n",
            "Episode: 687 Total reward: 199.0 Training loss: 0.2133 Explore P: 0.0255\n",
            "Episode: 688 Total reward: 199.0 Training loss: 0.3072 Explore P: 0.0252\n",
            "Episode: 689 Total reward: 199.0 Training loss: 0.1396 Explore P: 0.0249\n",
            "Episode: 690 Total reward: 199.0 Training loss: 0.1885 Explore P: 0.0246\n",
            "Episode: 691 Total reward: 199.0 Training loss: 0.2271 Explore P: 0.0243\n",
            "Episode: 692 Total reward: 199.0 Training loss: 0.1014 Explore P: 0.0240\n",
            "Episode: 693 Total reward: 199.0 Training loss: 0.2647 Explore P: 0.0237\n",
            "Episode: 694 Total reward: 199.0 Training loss: 0.0601 Explore P: 0.0235\n",
            "Episode: 695 Total reward: 199.0 Training loss: 0.3191 Explore P: 0.0232\n",
            "Episode: 696 Total reward: 199.0 Training loss: 0.3004 Explore P: 0.0230\n",
            "Episode: 697 Total reward: 199.0 Training loss: 0.1719 Explore P: 0.0227\n",
            "Episode: 698 Total reward: 199.0 Training loss: 3.8845 Explore P: 0.0224\n",
            "Episode: 699 Total reward: 199.0 Training loss: 219.0852 Explore P: 0.0222\n",
            "Episode: 700 Total reward: 199.0 Training loss: 13.7549 Explore P: 0.0220\n",
            "Episode: 701 Total reward: 199.0 Training loss: 0.0509 Explore P: 0.0217\n",
            "Episode: 702 Total reward: 199.0 Training loss: 0.1142 Explore P: 0.0215\n",
            "Episode: 703 Total reward: 199.0 Training loss: 0.1178 Explore P: 0.0213\n",
            "Episode: 704 Total reward: 199.0 Training loss: 0.2083 Explore P: 0.0210\n",
            "Episode: 705 Total reward: 199.0 Training loss: 0.1919 Explore P: 0.0208\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}