{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jax_mnist_classification_linear.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt5j_Px-cz7T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ee69e83-142d-4780-996f-327fc4300ddd"
      },
      "source": [
        "# TF CODE\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "\n",
        "seed=1234\n",
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['pythonhashseed'] = str(seed)\n",
        "    tf.random.set_random_seed(seed)\n",
        "seed_everything(seed)\n",
        "\n",
        "# Load data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "\n",
        "# Create the model\n",
        "x = tf.placeholder(tf.float32, [None, 784], name=\"x-input\")\n",
        "W = tf.Variable(tf.zeros([784,10]), name=\"weights\")\n",
        "b = tf.Variable(tf.zeros([10], name=\"bias\"))\n",
        "\n",
        "# use a name scope to organize nodes in the graph visualizer\n",
        "with tf.name_scope(\"Wx_b\") as scope:\n",
        "  y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
        "\n",
        "# Add summary ops to collect data\n",
        "w_hist = tf.summary.histogram(\"weights\", W)\n",
        "b_hist = tf.summary.histogram(\"biases\", b)\n",
        "y_hist = tf.summary.histogram(\"y\", y)\n",
        "\n",
        "# Define loss and optimizer\n",
        "y_ = tf.placeholder(tf.float32, [None, 10], name=\"y-input\")\n",
        "# More name scopes will clean up the graph representation\n",
        "with tf.name_scope(\"xent\") as scope:\n",
        "  cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
        "  ce_summ = tf.summary.scalar(\"cross_entropy\", cross_entropy)\n",
        "with tf.name_scope(\"train\") as scope:\n",
        "  train_step = tf.train.AdamOptimizer(0.02).minimize(cross_entropy)\n",
        "\n",
        "with tf.name_scope(\"test\") as scope:\n",
        "  correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "  accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)\n",
        "\n",
        "# Merge all the summaries and write them out to /tmp/mnist_lin\n",
        "merged = tf.summary.merge_all()\n",
        "sess = tf.Session()\n",
        "writer = tf.summary.FileWriter(\"./mnist_lin\", sess.graph_def)\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "# Train the model, and feed in test data and record summaries every 10 steps\n",
        "\n",
        "for i in range(1000):\n",
        "  if i % 10 == 0:  # Record summary data, and the accuracy\n",
        "    feed = {x: mnist.test.images, y_: mnist.test.labels}\n",
        "    result = sess.run([merged, accuracy], feed_dict=feed)\n",
        "    summary_str = result[0]\n",
        "    acc = result[1]\n",
        "    writer.add_summary(summary_str, i)\n",
        "    print(\"Accuracy at step %s: %s\" % (i, acc))\n",
        "  else:\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "    feed = {x: batch_xs, y_: batch_ys}\n",
        "    sess.run(train_step, feed_dict=feed)\n",
        "\n",
        "print(sess.run(accuracy, feed_dict = {x: mnist.test.images, y_: mnist.test.labels}))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-18da35bddfa4>:16: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n",
            "Accuracy at step 0: 0.098\n",
            "Accuracy at step 10: 0.7944\n",
            "Accuracy at step 20: 0.856\n",
            "Accuracy at step 30: 0.8835\n",
            "Accuracy at step 40: 0.8902\n",
            "Accuracy at step 50: 0.8884\n",
            "Accuracy at step 60: 0.8929\n",
            "Accuracy at step 70: 0.8997\n",
            "Accuracy at step 80: 0.9018\n",
            "Accuracy at step 90: 0.9023\n",
            "Accuracy at step 100: 0.8971\n",
            "Accuracy at step 110: 0.8935\n",
            "Accuracy at step 120: 0.8851\n",
            "Accuracy at step 130: 0.9002\n",
            "Accuracy at step 140: 0.9063\n",
            "Accuracy at step 150: 0.9025\n",
            "Accuracy at step 160: 0.9082\n",
            "Accuracy at step 170: 0.9054\n",
            "Accuracy at step 180: 0.9044\n",
            "Accuracy at step 190: 0.9118\n",
            "Accuracy at step 200: 0.9026\n",
            "Accuracy at step 210: 0.9069\n",
            "Accuracy at step 220: 0.9017\n",
            "Accuracy at step 230: 0.917\n",
            "Accuracy at step 240: 0.9052\n",
            "Accuracy at step 250: 0.9099\n",
            "Accuracy at step 260: 0.913\n",
            "Accuracy at step 270: 0.914\n",
            "Accuracy at step 280: 0.9072\n",
            "Accuracy at step 290: 0.9041\n",
            "Accuracy at step 300: 0.9058\n",
            "Accuracy at step 310: 0.9069\n",
            "Accuracy at step 320: 0.896\n",
            "Accuracy at step 330: 0.9089\n",
            "Accuracy at step 340: 0.9\n",
            "Accuracy at step 350: 0.9028\n",
            "Accuracy at step 360: 0.9065\n",
            "Accuracy at step 370: 0.8948\n",
            "Accuracy at step 380: 0.9044\n",
            "Accuracy at step 390: 0.9121\n",
            "Accuracy at step 400: 0.9046\n",
            "Accuracy at step 410: 0.9143\n",
            "Accuracy at step 420: 0.9157\n",
            "Accuracy at step 430: 0.9018\n",
            "Accuracy at step 440: 0.9036\n",
            "Accuracy at step 450: 0.9122\n",
            "Accuracy at step 460: 0.9113\n",
            "Accuracy at step 470: 0.9125\n",
            "Accuracy at step 480: 0.9015\n",
            "Accuracy at step 490: 0.9063\n",
            "Accuracy at step 500: 0.8961\n",
            "Accuracy at step 510: 0.9037\n",
            "Accuracy at step 520: 0.9053\n",
            "Accuracy at step 530: 0.9206\n",
            "Accuracy at step 540: 0.9127\n",
            "Accuracy at step 550: 0.9061\n",
            "Accuracy at step 560: 0.8837\n",
            "Accuracy at step 570: 0.9076\n",
            "Accuracy at step 580: 0.9044\n",
            "Accuracy at step 590: 0.9096\n",
            "Accuracy at step 600: 0.9088\n",
            "Accuracy at step 610: 0.9124\n",
            "Accuracy at step 620: 0.9169\n",
            "Accuracy at step 630: 0.901\n",
            "Accuracy at step 640: 0.9132\n",
            "Accuracy at step 650: 0.9182\n",
            "Accuracy at step 660: 0.9139\n",
            "Accuracy at step 670: 0.9106\n",
            "Accuracy at step 680: 0.9107\n",
            "Accuracy at step 690: 0.9126\n",
            "Accuracy at step 700: 0.9114\n",
            "Accuracy at step 710: 0.9109\n",
            "Accuracy at step 720: 0.9182\n",
            "Accuracy at step 730: 0.9087\n",
            "Accuracy at step 740: 0.9085\n",
            "Accuracy at step 750: 0.9066\n",
            "Accuracy at step 760: 0.8975\n",
            "Accuracy at step 770: 0.9053\n",
            "Accuracy at step 780: 0.9082\n",
            "Accuracy at step 790: 0.901\n",
            "Accuracy at step 800: 0.9136\n",
            "Accuracy at step 810: 0.9117\n",
            "Accuracy at step 820: 0.9149\n",
            "Accuracy at step 830: 0.9135\n",
            "Accuracy at step 840: 0.9033\n",
            "Accuracy at step 850: 0.9178\n",
            "Accuracy at step 860: 0.9164\n",
            "Accuracy at step 870: 0.9196\n",
            "Accuracy at step 880: 0.92\n",
            "Accuracy at step 890: 0.9168\n",
            "Accuracy at step 900: 0.9081\n",
            "Accuracy at step 910: 0.9104\n",
            "Accuracy at step 920: 0.9026\n",
            "Accuracy at step 930: 0.9112\n",
            "Accuracy at step 940: 0.9072\n",
            "Accuracy at step 950: 0.9002\n",
            "Accuracy at step 960: 0.8979\n",
            "Accuracy at step 970: 0.9094\n",
            "Accuracy at step 980: 0.9124\n",
            "Accuracy at step 990: 0.9035\n",
            "0.9167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "becKhrlUdqpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from jax import jit, grad, vmap, random\n",
        "from functools import partial\n",
        "import jax\n",
        "import jax.numpy as np\n",
        "from jax.experimental import stax # neural network library\n",
        "from jax.experimental.stax import Conv, Dense, MaxPool, Relu, Flatten, LogSoftmax, LeakyRelu, Dropout # neural network layers\n",
        "from jax.nn import softmax\n",
        "from jax.nn.initializers import zeros\n",
        "import matplotlib.pyplot as plt # visualization\n",
        "import numpy as onp\n",
        "from jax.experimental import optimizers\n",
        "from jax.tree_util import tree_multimap  # Element-wise manipulation of collections of numpy arrays"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ0E5vMreUAf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "dfc9fc37-1f9a-43f5-df02-88903f49fb53"
      },
      "source": [
        "# Load data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
        "rng = random.PRNGKey(1)\n",
        "print(mnist.train.images.shape, mnist.train.labels.shape, mnist.test.images.shape, mnist.test.labels.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "(55000, 784) (55000, 10) (10000, 784) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8xfYmsXe8K9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "07016daa-65d9-4bc9-8d40-de42a01297c6"
      },
      "source": [
        "#Define model\n",
        "in_dim = mnist.train.images.shape[-1]\n",
        "out_dim = mnist.train.labels.shape[-1]\n",
        "_, net_apply = Dense(out_dim)\n",
        "in_shape = (-1, in_dim)\n",
        "net_params = np.zeros((in_dim,out_dim)), np.zeros((1,out_dim))\n",
        "print(net_params)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(_FilledConstant([[0., 0., 0., ..., 0., 0., 0.],\n",
            "                 [0., 0., 0., ..., 0., 0., 0.],\n",
            "                 [0., 0., 0., ..., 0., 0., 0.],\n",
            "                 ...,\n",
            "                 [0., 0., 0., ..., 0., 0., 0.],\n",
            "                 [0., 0., 0., ..., 0., 0., 0.],\n",
            "                 [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), _FilledConstant([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKTNnylSfXCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define losses and optimizers\n",
        "def loss(params, inputs, targets):\n",
        "    # Computes average loss for the batch\n",
        "    predictions = softmax(net_apply(params, inputs), axis=-1)\n",
        "    print(targets, predictions)\n",
        "    return -np.sum(targets*np.log(predictions))\n",
        "\n",
        "def batch_loss(params, inputs, targets):\n",
        "    losses=vmap(partial(loss, params))(inputs, targets)\n",
        "    return np.mean(losses)\n",
        "\n",
        "def accuracy(params, inputs, targets):\n",
        "    predictions = softmax(net_apply(params, inputs), axis=-1)\n",
        "    correct_prediction = np.equal(np.argmax(targets,-1), np.argmax(predictions,-1))\n",
        "    return np.mean(correct_prediction)\n",
        "\n",
        "opt_init, opt_update, get_params = optimizers.adam(step_size=0.01)  # this LR seems to be better than 1e-2 and 1e-4\n",
        "# out_shape, net_params = net_init(rng, in_shape)\n",
        "net_params = np.zeros((in_dim,out_dim)), np.zeros((1,out_dim))\n",
        "opt_state = opt_init(net_params)\n",
        "\n",
        "@jit\n",
        "def step(i, opt_state, x, y):\n",
        "    p = get_params(opt_state)\n",
        "    g = grad(batch_loss)(p, x, y)\n",
        "    l = batch_loss(p, x, y)\n",
        "    return opt_update(i, g, opt_state), l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-mo3kE5jELG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c8d5b6e-e330-42ce-bdca-54a424bd1004"
      },
      "source": [
        "#Training\n",
        "losses=[]\n",
        "for i in range(1000):\n",
        "    if i % 10 == 0:\n",
        "        # print(i, mnist.test.images.shape, mnist.test.labels.shape)\n",
        "        current_params = get_params(opt_state)\n",
        "        print(\"Accuracy at step %s: %s\" % (i, accuracy(current_params, mnist.test.images, mnist.test.labels)))\n",
        "    else:\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "        opt_state, l = step(i, opt_state, batch_xs, batch_ys)\n",
        "        losses.append(l)\n",
        "        #print(l)\n",
        "net_params=get_params(opt_state)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy at step 0: 0.098000005\n",
            "Traced<ShapedArray(float32[10])>with<BatchTrace(level=2/1)> Traced<ShapedArray(float32[1,10])>with<BatchTrace(level=2/1)>\n",
            "Traced<ShapedArray(float32[10])>with<BatchTrace(level=0/1)> Traced<ShapedArray(float32[1,10])>with<BatchTrace(level=0/1)>\n",
            "Accuracy at step 10: 0.80660003\n",
            "Accuracy at step 20: 0.84560007\n",
            "Accuracy at step 30: 0.86490005\n",
            "Accuracy at step 40: 0.88080007\n",
            "Accuracy at step 50: 0.88290006\n",
            "Accuracy at step 60: 0.89230007\n",
            "Accuracy at step 70: 0.89330006\n",
            "Accuracy at step 80: 0.89750004\n",
            "Accuracy at step 90: 0.89480007\n",
            "Accuracy at step 100: 0.90080005\n",
            "Accuracy at step 110: 0.9035\n",
            "Accuracy at step 120: 0.90250003\n",
            "Accuracy at step 130: 0.90250003\n",
            "Accuracy at step 140: 0.9039\n",
            "Accuracy at step 150: 0.9046\n",
            "Accuracy at step 160: 0.90760005\n",
            "Accuracy at step 170: 0.91240007\n",
            "Accuracy at step 180: 0.90860003\n",
            "Accuracy at step 190: 0.91470003\n",
            "Accuracy at step 200: 0.9064\n",
            "Accuracy at step 210: 0.9096\n",
            "Accuracy at step 220: 0.9110001\n",
            "Accuracy at step 230: 0.9153001\n",
            "Accuracy at step 240: 0.9085\n",
            "Accuracy at step 250: 0.91590005\n",
            "Accuracy at step 260: 0.9153001\n",
            "Accuracy at step 270: 0.90970004\n",
            "Accuracy at step 280: 0.9089\n",
            "Accuracy at step 290: 0.91450006\n",
            "Accuracy at step 300: 0.90910006\n",
            "Accuracy at step 310: 0.91170007\n",
            "Accuracy at step 320: 0.9092001\n",
            "Accuracy at step 330: 0.915\n",
            "Accuracy at step 340: 0.9121\n",
            "Accuracy at step 350: 0.91700006\n",
            "Accuracy at step 360: 0.91590005\n",
            "Accuracy at step 370: 0.90790004\n",
            "Accuracy at step 380: 0.91\n",
            "Accuracy at step 390: 0.90760005\n",
            "Accuracy at step 400: 0.9103\n",
            "Accuracy at step 410: 0.9171001\n",
            "Accuracy at step 420: 0.91480005\n",
            "Accuracy at step 430: 0.91630006\n",
            "Accuracy at step 440: 0.91420007\n",
            "Accuracy at step 450: 0.91290003\n",
            "Accuracy at step 460: 0.9164\n",
            "Accuracy at step 470: 0.91670007\n",
            "Accuracy at step 480: 0.9082\n",
            "Accuracy at step 490: 0.91420007\n",
            "Accuracy at step 500: 0.9064\n",
            "Accuracy at step 510: 0.91840005\n",
            "Accuracy at step 520: 0.91770005\n",
            "Accuracy at step 530: 0.9186\n",
            "Accuracy at step 540: 0.92050004\n",
            "Accuracy at step 550: 0.92170006\n",
            "Accuracy at step 560: 0.91410005\n",
            "Accuracy at step 570: 0.91700006\n",
            "Accuracy at step 580: 0.91340005\n",
            "Accuracy at step 590: 0.9143\n",
            "Accuracy at step 600: 0.9146\n",
            "Accuracy at step 610: 0.9179\n",
            "Accuracy at step 620: 0.92100006\n",
            "Accuracy at step 630: 0.91800004\n",
            "Accuracy at step 640: 0.91560006\n",
            "Accuracy at step 650: 0.91780007\n",
            "Accuracy at step 660: 0.91850007\n",
            "Accuracy at step 670: 0.9189001\n",
            "Accuracy at step 680: 0.9168\n",
            "Accuracy at step 690: 0.9171001\n",
            "Accuracy at step 700: 0.91810006\n",
            "Accuracy at step 710: 0.91590005\n",
            "Accuracy at step 720: 0.9207001\n",
            "Accuracy at step 730: 0.91950005\n",
            "Accuracy at step 740: 0.91240007\n",
            "Accuracy at step 750: 0.91880006\n",
            "Accuracy at step 760: 0.91590005\n",
            "Accuracy at step 770: 0.91370004\n",
            "Accuracy at step 780: 0.9215\n",
            "Accuracy at step 790: 0.91730005\n",
            "Accuracy at step 800: 0.91740006\n",
            "Accuracy at step 810: 0.9186\n",
            "Accuracy at step 820: 0.91580003\n",
            "Accuracy at step 830: 0.91740006\n",
            "Accuracy at step 840: 0.9132\n",
            "Accuracy at step 850: 0.91830003\n",
            "Accuracy at step 860: 0.9175\n",
            "Accuracy at step 870: 0.91990006\n",
            "Accuracy at step 880: 0.9172\n",
            "Accuracy at step 890: 0.91520005\n",
            "Accuracy at step 900: 0.91170007\n",
            "Accuracy at step 910: 0.91510004\n",
            "Accuracy at step 920: 0.9157\n",
            "Accuracy at step 930: 0.92050004\n",
            "Accuracy at step 940: 0.9146\n",
            "Accuracy at step 950: 0.9118\n",
            "Accuracy at step 960: 0.9114\n",
            "Accuracy at step 970: 0.91830003\n",
            "Accuracy at step 980: 0.9186\n",
            "Accuracy at step 990: 0.92010003\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}